{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xe_J1YFCOBcF"
      },
      "source": [
        "# **Autoencoders in Computer Vision - Jupyter Notebook Tutorial**\n",
        "\n",
        "# Section 1: Introduction to Autoencoders\n",
        "\n",
        "\n",
        "NOTES:\n",
        "Autoencoders are neural networks designed to learn compressed representations of data.\n",
        "They work by encoding the input into a latent space and then decoding it back to reconstruct the input.\n",
        "\n",
        "This is useful in scenarios where labeled data is scarce but we still want to learn meaningful features.\n",
        "The learned features (latent vectors) are useful for:\n",
        "- Image compression\n",
        "- Noise reduction (denoising autoencoders)\n",
        "- Anomaly detection (reconstruction error)\n",
        "- Pretraining for classification or generative models\n",
        "- Transfer learning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vxOVlI62OR1O"
      },
      "source": [
        "# Section 2: Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Byyw-rPODNu",
        "outputId": "6e37092b-b627-439e-f9a7-272156546c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfOGsj1SOal6"
      },
      "source": [
        "# Section 3: Load Dataset (MNIST)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUtE8gEIObH6",
        "outputId": "e7703fde-c179-4bd1-ab26-b7be9e5c1c98"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.51MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 160kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.52MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.94MB/s]\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_data, val_data = random_split(dataset, [50000, 10000])\n",
        "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkXc0neROfwC"
      },
      "source": [
        "# Section 4: Define Basic Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QkXMwLXeOgS-"
      },
      "outputs": [],
      "source": [
        "class Autoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28*28, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 64)\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(64, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 28*28),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Unflatten(1, (1, 28, 28))\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.encoder(x)\n",
        "        out = self.decoder(z)\n",
        "        return out\n",
        "\n",
        "model = Autoencoder().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JputTLV_OjaB"
      },
      "source": [
        "# Section 5: Training Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oIAX5dkOk7K",
        "outputId": "a8ce7e9b-01e7-4e69-af15-9c88287cbd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.0189\n",
            "Epoch 2/5, Loss: 0.0109\n",
            "Epoch 3/5, Loss: 0.0077\n",
            "Epoch 4/5, Loss: 0.0091\n",
            "Epoch 5/5, Loss: 0.0095\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    for images, _ in train_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, images)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozEZG8qoOnnD"
      },
      "source": [
        "# Section 6: Visualize Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE_DgJSpOpiT"
      },
      "outputs": [],
      "source": [
        "def show_reconstruction():\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, _ in train_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            break\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2)\n",
        "    axes[0].imshow(images[0].cpu().squeeze(), cmap='gray')\n",
        "    axes[0].set_title(\"Original\")\n",
        "    axes[1].imshow(outputs[0].cpu().squeeze(), cmap='gray')\n",
        "    axes[1].set_title(\"Reconstructed\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXgqGlBHOs6-"
      },
      "source": [
        " After visualizing the reconstructed images, the goal is to evaluate how well the model learned the compressed representation.\n",
        "    If the reconstruction is good, it means the encoder has captured the essential information.\n",
        "\n",
        "    These latent features can now be reused:\n",
        "    - For clustering similar images\n",
        "    - As inputs to a classifier\n",
        "    - As building blocks for generative models like Variational Autoencoders or GANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-RLdMLLO9vG"
      },
      "outputs": [],
      "source": [
        "show_reconstruction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5wVQQjqO_zL"
      },
      "source": [
        "# Section 7: Classification Using Latent Features\n",
        "\n",
        "We now use the encoder's output (latent vector) to train a simple classifier.\n",
        "This demonstrates the power of unsupervised representation learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utdaSNzNPAUU"
      },
      "outputs": [],
      "source": [
        "class LatentClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LatentClassifier, self).__init__()\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.fc(z)\n",
        "\n",
        "classifier = LatentClassifier().to(device)\n",
        "clf_criterion = nn.CrossEntropyLoss()\n",
        "clf_optimizer = optim.Adam(classifier.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FzNjbT7POHy"
      },
      "source": [
        "# Train the classifier using frozen encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JENDg-RhPPw-"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6-Odc99PQ0J"
      },
      "source": [
        "# Classification training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyyP7ExXPTbS"
      },
      "outputs": [],
      "source": [
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    classifier.train()\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            z = model.encoder(images)\n",
        "        preds = classifier(z)\n",
        "        loss = clf_criterion(preds, labels)\n",
        "\n",
        "        clf_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        clf_optimizer.step()\n",
        "\n",
        "    print(f\"[Classifier] Epoch {epoch+1}, Loss: {loss.item():.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZU4HqicPV03"
      },
      "source": [
        "# Evaluate classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPzu4E9fPXQy"
      },
      "outputs": [],
      "source": [
        "correct, total = 0, 0\n",
        "classifier.eval()\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        z = model.encoder(images)\n",
        "        preds = classifier(z)\n",
        "        predicted = preds.argmax(1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "print(f\"Validation Accuracy using latent features: {100 * correct / total:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCNOKZHcPiOI"
      },
      "source": [
        "# Final Notes:\n",
        "\n",
        "We explored basic and masked autoencoders in this notebook.\n",
        "They enable learning rich visual representations without any labels.\n",
        "\n",
        "By training to reconstruct input images or masked portions,\n",
        "autoencoders learn **meaningful features** that capture underlying structure in the data.\n",
        "These features can be used as a foundation for other computer vision tasks:\n",
        "- Classification (as demonstrated)\n",
        "- Clustering\n",
        "- Generative Modeling (e.g. VAEs, GANs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofLRGeK9PkB8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
