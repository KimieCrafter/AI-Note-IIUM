{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1P5KUInW6uY"
      },
      "source": [
        "## Import and dataloaders\n",
        "\n",
        "Before starting this tutorial, let's  import and define our dataloaders for CIFAR10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuPXfbU0XFIw",
        "outputId": "9eae08f2-54e5-4273-d414-9d08030d9aeb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "torchvision version: 0.20.1+cu121\n"
          ]
        }
      ],
      "source": [
        "# Import PyTorch\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Import torchvision\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "# from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Import matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check versions\n",
        "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
        "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Nq55v6GXSqi",
        "outputId": "d1865748-fea2-4f05-d7b0-cae924b2ee1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "class CIFAR10Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root='./data', train=True, transform=None, download=True):\n",
        "        self.data = torchvision.datasets.CIFAR10(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]  # Returns (image, label) tuple\n",
        "\n",
        "def get_dataloader(batch_size=4, num_workers=0, root='./data'):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    train_dataset = CIFAR10Dataset(root=root, train=True, transform=transform)\n",
        "    test_dataset = CIFAR10Dataset(root=root, train=False, transform=transform)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "\n",
        "    return train_dataloader, test_dataloader\n",
        "\n",
        "# Get dataloaders\n",
        "train_dataloader, test_dataloader = get_dataloader(batch_size=16, num_workers=0)\n",
        "\n",
        "# Define class names\n",
        "class_names = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "batch_size = 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OANDTmKwXYww",
        "outputId": "112ae28b-2198-4c7e-e877-f40b67bb0e0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x00000167869D5F30>, <torch.utils.data.dataloader.DataLoader object at 0x00000167869D6AD0>)\n",
            "Length of train dataloader: 3125 batches of 16\n",
            "Length of test dataloader: 625 batches of 16\n"
          ]
        }
      ],
      "source": [
        "# Let's check out what we've created\n",
        "print(f\"Dataloaders: {train_dataloader, test_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {batch_size}\")\n",
        "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVihl7rPFO9W"
      },
      "source": [
        "## Batch Normalization and Dropout\n",
        "\n",
        "Discover how batch normalization and dropout improve a model's accuracy.\n",
        "\n",
        "We will be covering:\n",
        "\n",
        "- Batch Normalization\n",
        "\n",
        "- Notations\n",
        "\n",
        "- Advantages and disadvantages of using batch normalization\n",
        "\n",
        "- Dropout\n",
        "\n",
        "### Batch Normalization\n",
        "\n",
        "If you open any introductory machine learning textbook, you will find the idea of **input scaling**. It is undesirable to train a model with **gradient descent** with non-normalized input features.\n",
        "\n",
        "Let’s start with an intuitive example to understand why we want normalization inside any model.\n",
        "\n",
        "Suppose you have an input feature $x1$ in the range [0,10000] and another feature $x2$ in the range [0,1]. Any linear combination would ignore $x2$ such that $x1*w1 + x2*w2 \\approx x1$, since our weights are initialized in a very tiny range like [-1,1].\n",
        "\n",
        "We encounter the same issues inside the layers of deep neural networks. In this lesson, we will propagate this idea inside the NN.\n",
        "\n",
        "> If we think out of the box, any intermediate layer is conceptually the same as the input layer; it accepts features and transforms them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78X-xhlyFO9y"
      },
      "source": [
        "### Notations\n",
        "\n",
        "Throughout this lesson, $N$ will be the batch size, $H$ will refer to the height, $W$ to the width, and $C$ to the feature channels. The greek letter $\\mu()$ refers to mean and the greek letter $\\sigma()$ refers to standard deviation.\n",
        "\n",
        "The batch features are denoted by $x$ with a shape of $[N, C, H, W]$.\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig22.PNG)\n",
        "\n",
        "We will visualize the 4D activation maps x by **merging the spatial dimensions**. Now, we have a 3D shape that looks like this:\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig23.PNG)\n",
        "\n",
        "The most dominant solution is batch normalization. Let’s see how it works.\n",
        "\n",
        "> Batch Normalization (BN) normalizes the mean and standard deviation **for each individual feature channel/map**.\n",
        "\n",
        "First of all, the mean and standard deviation are first-order statistics, and thus they relate to the **global characteristics** (such as the image style).\n",
        "\n",
        "In this way, we somehow blend the global characteristics. Such a strategy is effective when we want our representation to share these characteristics. This is the reason that we widely utilize BN in downstream tasks (i.e., image classification).\n",
        "\n",
        "From a mathematical point of view, **you can think of it as bringing the features of the image in the same range**.\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig24.PNG)\n",
        "\n",
        "Specifically, we demand from our features to follow a Gaussian distribution with zero mean and unit variance. Mathematically, this can be expressed as:\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig25.PNG)\n",
        "\n",
        "The index $c$ denotes the per-channel (feature map) mean.\n",
        "\n",
        "Let’s see this operation visually:\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig26.PNG)\n",
        "\n",
        "Notably, the spatial dimensions as well as the image batch are averaged. This way, **we concentrate our features in a compact Gaussian-like space**, which is usually beneficial.\n",
        "\n",
        "In fact, $\\gamma$ and $\\beta$ correspond to the trainable parameters that result in the linear/affine transformation, which is different for all channels.\n",
        "\n",
        "Specifically $\\gamma$ and $\\beta$ are vectors with the channel dimensionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq4OEKm3FO95"
      },
      "source": [
        "### Advantages and disadvantages of using batch normalization\n",
        "\n",
        "The following are some **advantages** of BN:\n",
        "\n",
        "- BN accelerates the training of deep neural networks and tackles the vanishing gradient problem.\n",
        "\n",
        "- For every input mini-batch, we calculate different statistics. This introduces some sort of regularization. Regularization refers to any form of technique/constraint that restricts the complexity of a deep neural network during training.\n",
        "\n",
        "- BN also has a beneficial effect on the gradient flow through the network. It reduces the dependence of gradients on the scale of the parameters or of their initial values. This allows us to use much higher learning rates.\n",
        "\n",
        "- In theory, BN makes it possible to use saturating nonlinearities by preventing the network from getting stuck, but we just use nn.ReLU().\n",
        "\n",
        "- BN makes the gradients more predictive.\n",
        "\n",
        "BN has the following **disadvantages**:\n",
        "\n",
        "- Batch normalization may cause inaccurate estimation of batch statistics when we have a small batch size. This increases the model error. In tasks such as image segmentation, the batch size is usually too small. BN needs a sufficiently large batch size.\n",
        "\n",
        "Let’s now implement batch normalization from scratch for images of size $[N, C, H, W]$. All you have to do is transform the above equations to Pytorch. The tricky part is to correctly figure out the sizes of each tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c9RMg8gtFO9-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Gamma and beta are provided as 1d tensors.\n",
        "# X is the data in a mini-batch\n",
        "\n",
        "def batchnorm(X, gamma, beta):\n",
        "\n",
        "    # extract the dimensions\n",
        "    N, C, H, W = list(X.size())\n",
        "    # mini-batch mean\n",
        "    mean = torch.mean(X, dim=(0, 2, 3))\n",
        "    # mini-batch variance\n",
        "    variance = torch.mean((X - mean.reshape((1, C, 1, 1))) ** 2, dim=(0, 2, 3))\n",
        "    # normalize\n",
        "    X_hat = (X - mean.reshape((1, C, 1, 1))) * 1.0 / torch.sqrt(variance.reshape((1, C, 1, 1)) )\n",
        "    # scale and shift\n",
        "    out = gamma.reshape((1, C, 1, 1)) * X_hat + beta.reshape((1, C, 1, 1))\n",
        "\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Xiiu6gbyXiV5"
      },
      "outputs": [],
      "source": [
        "# get some random training images\n",
        "dataiter = iter(train_dataloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "BN_layer = nn.BatchNorm2d(3)\n",
        "output_BN = BN_layer(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CuOAqYKUzwfv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.1765,  0.3098,  0.3569,  ...,  0.2392,  0.2157,  0.2549],\n",
            "          [ 0.2078,  0.2863,  0.3255,  ...,  0.1765,  0.1608,  0.2078],\n",
            "          [ 0.2157,  0.2235,  0.2941,  ...,  0.2471,  0.2784,  0.3490],\n",
            "          ...,\n",
            "          [ 0.2549,  0.2000,  0.1922,  ...,  0.3176,  0.3569,  0.3255],\n",
            "          [ 0.2000,  0.1765,  0.1922,  ...,  0.2706,  0.3412,  0.3804],\n",
            "          [ 0.1843,  0.1608,  0.1294,  ...,  0.3098,  0.3647,  0.3569]],\n",
            "\n",
            "         [[ 0.0745,  0.2078,  0.2549,  ...,  0.1686,  0.1529,  0.1922],\n",
            "          [ 0.0980,  0.1843,  0.2235,  ...,  0.1059,  0.0980,  0.1451],\n",
            "          [ 0.1137,  0.1216,  0.1922,  ...,  0.1843,  0.2157,  0.2863],\n",
            "          ...,\n",
            "          [ 0.1922,  0.1373,  0.1294,  ...,  0.2392,  0.2784,  0.2471],\n",
            "          [ 0.1373,  0.1137,  0.1294,  ...,  0.1922,  0.2627,  0.3020],\n",
            "          [ 0.1216,  0.0980,  0.0667,  ...,  0.2314,  0.2863,  0.2784]],\n",
            "\n",
            "         [[ 0.0275,  0.1608,  0.2078,  ...,  0.1608,  0.1373,  0.1765],\n",
            "          [ 0.0510,  0.1373,  0.1765,  ...,  0.0980,  0.0824,  0.1294],\n",
            "          [ 0.0667,  0.0745,  0.1451,  ...,  0.1765,  0.2000,  0.2706],\n",
            "          ...,\n",
            "          [ 0.1765,  0.1216,  0.1137,  ...,  0.2157,  0.2627,  0.2314],\n",
            "          [ 0.1216,  0.0980,  0.1137,  ...,  0.1765,  0.2471,  0.2863],\n",
            "          [ 0.0980,  0.0824,  0.0510,  ...,  0.2078,  0.2706,  0.2627]]],\n",
            "\n",
            "\n",
            "        [[[-0.7255, -0.5373, -0.3569,  ..., -0.8902, -0.8824, -0.8980],\n",
            "          [-0.6627, -0.5216, -0.3882,  ..., -0.8980, -0.8902, -0.8902],\n",
            "          [-0.6000, -0.5137, -0.4431,  ..., -0.8902, -0.8824, -0.8824],\n",
            "          ...,\n",
            "          [-0.0588, -0.0824, -0.0902,  ..., -0.0196,  0.0824,  0.0275],\n",
            "          [-0.0588, -0.0667, -0.0510,  ..., -0.0667, -0.0353, -0.0196],\n",
            "          [-0.0510, -0.0118,  0.0510,  ..., -0.0902, -0.0902, -0.0824]],\n",
            "\n",
            "         [[-0.7647, -0.6078, -0.4431,  ..., -0.8745, -0.8745, -0.8902],\n",
            "          [-0.7490, -0.6314, -0.5059,  ..., -0.8824, -0.8745, -0.8745],\n",
            "          [-0.6941, -0.6314, -0.5608,  ..., -0.8902, -0.8824, -0.8824],\n",
            "          ...,\n",
            "          [-0.0902, -0.1137, -0.1216,  ..., -0.0745,  0.0196, -0.0275],\n",
            "          [-0.0902, -0.0980, -0.0745,  ..., -0.1294, -0.1059, -0.0902],\n",
            "          [-0.0745, -0.0353,  0.0275,  ..., -0.1686, -0.1765, -0.1765]],\n",
            "\n",
            "         [[-0.8588, -0.6471, -0.4980,  ..., -0.9216, -0.9216, -0.9373],\n",
            "          [-0.7882, -0.6784, -0.6000,  ..., -0.9216, -0.9137, -0.9137],\n",
            "          [-0.7176, -0.7333, -0.7412,  ..., -0.9451, -0.9373, -0.9373],\n",
            "          ...,\n",
            "          [-0.1843, -0.2078, -0.2157,  ..., -0.1608, -0.0667, -0.1216],\n",
            "          [-0.1922, -0.1922, -0.1765,  ..., -0.2471, -0.2157, -0.2000],\n",
            "          [-0.1922, -0.1529, -0.0902,  ..., -0.3098, -0.3098, -0.2941]]],\n",
            "\n",
            "\n",
            "        [[[-0.1765, -0.1451, -0.1608,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.1843, -0.1608, -0.1843,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.2157, -0.1922, -0.2235,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 0.5843,  0.5608,  0.4588,  ...,  0.5686,  0.5608,  0.5608],\n",
            "          [ 0.5137,  0.5216,  0.4667,  ...,  0.5608,  0.5451,  0.5373],\n",
            "          [ 0.4902,  0.5216,  0.5529,  ...,  0.5608,  0.5608,  0.5529]],\n",
            "\n",
            "         [[-0.1765, -0.1529, -0.1608,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.1765, -0.1529, -0.1765,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.1843, -0.1686, -0.1922,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 0.5843,  0.5608,  0.4510,  ...,  0.5686,  0.5608,  0.5529],\n",
            "          [ 0.5059,  0.5137,  0.4510,  ...,  0.5529,  0.5373,  0.5294],\n",
            "          [ 0.4824,  0.5137,  0.5451,  ...,  0.5529,  0.5529,  0.5451]],\n",
            "\n",
            "         [[-0.1137, -0.0824, -0.1059,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.1137, -0.0902, -0.1294,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [-0.1373, -0.1137, -0.1451,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          ...,\n",
            "          [ 0.5529,  0.5216,  0.4039,  ...,  0.5608,  0.5529,  0.5294],\n",
            "          [ 0.4745,  0.4824,  0.4196,  ...,  0.5294,  0.5216,  0.5137],\n",
            "          [ 0.4667,  0.4980,  0.5216,  ...,  0.5373,  0.5373,  0.5294]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.8667,  0.8902,  0.9294,  ...,  1.0000,  1.0000,  1.0000],\n",
            "          [ 0.8588,  0.8902,  0.9216,  ...,  0.9922,  0.9843,  0.9765],\n",
            "          [ 0.9059,  0.9216,  0.9373,  ...,  0.9529,  0.9294,  0.9216],\n",
            "          ...,\n",
            "          [ 0.7490,  0.7333,  0.6471,  ...,  0.7804,  0.8667,  0.9294],\n",
            "          [ 0.7647,  0.7333,  0.6235,  ...,  0.8275,  0.9216,  0.9216],\n",
            "          [ 0.6157,  0.7647,  0.9294,  ...,  0.6941,  0.7569,  0.8118]],\n",
            "\n",
            "         [[ 0.8667,  0.8824,  0.9059,  ...,  1.0000,  1.0000,  0.9922],\n",
            "          [ 0.8588,  0.8824,  0.8980,  ...,  0.9922,  0.9922,  0.9843],\n",
            "          [ 0.8980,  0.9059,  0.9137,  ...,  0.9608,  0.9529,  0.9686],\n",
            "          ...,\n",
            "          [ 0.6235,  0.5922,  0.4667,  ...,  0.6941,  0.8118,  0.8980],\n",
            "          [ 0.6941,  0.5922,  0.4275,  ...,  0.7176,  0.8667,  0.8980],\n",
            "          [ 0.5765,  0.6706,  0.7725,  ...,  0.4824,  0.5843,  0.6863]],\n",
            "\n",
            "         [[ 0.8980,  0.9216,  0.9451,  ...,  0.8275,  0.8196,  0.8431],\n",
            "          [ 0.8902,  0.9216,  0.9451,  ...,  0.8275,  0.8118,  0.8353],\n",
            "          [ 0.9373,  0.9451,  0.9608,  ...,  0.8745,  0.8588,  0.8902],\n",
            "          ...,\n",
            "          [ 0.5922,  0.4980,  0.3176,  ...,  0.4510,  0.5137,  0.5922],\n",
            "          [ 0.5608,  0.3647,  0.1216,  ...,  0.3804,  0.5294,  0.6078],\n",
            "          [ 0.4196,  0.4039,  0.4118,  ...,  0.2706,  0.3804,  0.5294]]],\n",
            "\n",
            "\n",
            "        [[[-0.0510, -0.0745, -0.0980,  ..., -0.3882, -0.3961, -0.4118],\n",
            "          [-0.0431, -0.0824, -0.0980,  ..., -0.3725, -0.4196, -0.3961],\n",
            "          [-0.0902, -0.1294, -0.1373,  ..., -0.2314, -0.4510, -0.4275],\n",
            "          ...,\n",
            "          [ 0.9843,  0.9843,  1.0000,  ..., -0.7098, -0.7569, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.9922,  ..., -0.7569, -0.7255, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.8980,  ..., -0.7804, -0.7098, -0.6784]],\n",
            "\n",
            "         [[-0.0510, -0.0745, -0.0980,  ..., -0.3882, -0.3961, -0.4118],\n",
            "          [-0.0431, -0.0824, -0.0980,  ..., -0.3490, -0.4196, -0.3961],\n",
            "          [-0.0902, -0.1294, -0.1373,  ..., -0.1922, -0.4510, -0.4275],\n",
            "          ...,\n",
            "          [ 0.9843,  0.9843,  1.0000,  ..., -0.7098, -0.7569, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.9922,  ..., -0.7569, -0.7255, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.8980,  ..., -0.7804, -0.7098, -0.6784]],\n",
            "\n",
            "         [[-0.0510, -0.0745, -0.0980,  ..., -0.3961, -0.3961, -0.4118],\n",
            "          [-0.0431, -0.0824, -0.0980,  ..., -0.3333, -0.4196, -0.3961],\n",
            "          [-0.0902, -0.1294, -0.1373,  ..., -0.1608, -0.4588, -0.4275],\n",
            "          ...,\n",
            "          [ 0.9843,  0.9843,  1.0000,  ..., -0.7098, -0.7569, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.9922,  ..., -0.7569, -0.7255, -0.7255],\n",
            "          [ 0.9922,  0.9765,  0.8980,  ..., -0.7804, -0.7098, -0.6784]]],\n",
            "\n",
            "\n",
            "        [[[ 0.9922,  0.9843,  0.9843,  ...,  0.9686,  0.9765,  0.9843],\n",
            "          [ 0.9608,  0.9608,  0.9686,  ...,  0.9529,  0.9608,  0.9686],\n",
            "          [ 0.9529,  0.9608,  0.9686,  ...,  0.9608,  0.9843,  0.9843],\n",
            "          ...,\n",
            "          [-0.8353, -0.8745, -0.8824,  ...,  0.8745,  0.9686,  0.5765],\n",
            "          [-0.8824, -0.8902, -0.8824,  ...,  0.9137,  0.9686,  0.9216],\n",
            "          [-0.8824, -0.8902, -0.8824,  ...,  0.7882,  0.8667,  0.8745]],\n",
            "\n",
            "         [[ 0.7020,  0.6863,  0.6941,  ...,  0.7333,  0.7412,  0.7490],\n",
            "          [ 0.6706,  0.6706,  0.6784,  ...,  0.7176,  0.7255,  0.7333],\n",
            "          [ 0.6627,  0.6706,  0.6784,  ...,  0.7255,  0.7490,  0.7490],\n",
            "          ...,\n",
            "          [-0.8275, -0.8902, -0.9059,  ...,  0.6078,  0.7804,  0.4353],\n",
            "          [-0.8824, -0.8980, -0.9137,  ...,  0.6784,  0.8353,  0.8667],\n",
            "          [-0.8824, -0.9059, -0.9137,  ...,  0.4353,  0.6000,  0.6706]],\n",
            "\n",
            "         [[ 0.1451,  0.1373,  0.1373,  ...,  0.2392,  0.2471,  0.2549],\n",
            "          [ 0.1216,  0.1216,  0.1294,  ...,  0.2314,  0.2471,  0.2471],\n",
            "          [ 0.1137,  0.1216,  0.1294,  ...,  0.2392,  0.2627,  0.2627],\n",
            "          ...,\n",
            "          [-0.8196, -0.8745, -0.8980,  ...,  0.1373,  0.4118,  0.1529],\n",
            "          [-0.8824, -0.8980, -0.9059,  ...,  0.3255,  0.5608,  0.6392],\n",
            "          [-0.8824, -0.8980, -0.9059,  ...,  0.0980,  0.2941,  0.3961]]]])\n"
          ]
        }
      ],
      "source": [
        "print(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "U0iv6oB0zzGd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[[ 3.8694e-01,  6.5245e-01,  7.4616e-01,  ...,  5.1189e-01,\n",
            "            4.6503e-01,  5.4312e-01],\n",
            "          [ 4.4941e-01,  6.0560e-01,  6.8369e-01,  ...,  3.8694e-01,\n",
            "            3.5570e-01,  4.4941e-01],\n",
            "          [ 4.6503e-01,  4.8065e-01,  6.2121e-01,  ...,  5.2750e-01,\n",
            "            5.8998e-01,  7.3054e-01],\n",
            "          ...,\n",
            "          [ 5.4312e-01,  4.3380e-01,  4.1818e-01,  ...,  6.6807e-01,\n",
            "            7.4616e-01,  6.8369e-01],\n",
            "          [ 4.3380e-01,  3.8694e-01,  4.1818e-01,  ...,  5.7436e-01,\n",
            "            7.1492e-01,  7.9301e-01],\n",
            "          [ 4.0256e-01,  3.5570e-01,  2.9323e-01,  ...,  6.5245e-01,\n",
            "            7.6178e-01,  7.4616e-01]],\n",
            "\n",
            "         [[ 3.2314e-01,  6.0498e-01,  7.0445e-01,  ...,  5.2209e-01,\n",
            "            4.8893e-01,  5.7182e-01],\n",
            "          [ 3.7288e-01,  5.5524e-01,  6.3814e-01,  ...,  3.8946e-01,\n",
            "            3.7288e-01,  4.7235e-01],\n",
            "          [ 4.0604e-01,  4.2261e-01,  5.7182e-01,  ...,  5.5524e-01,\n",
            "            6.2156e-01,  7.7077e-01],\n",
            "          ...,\n",
            "          [ 5.7182e-01,  4.5577e-01,  4.3919e-01,  ...,  6.7129e-01,\n",
            "            7.5419e-01,  6.8787e-01],\n",
            "          [ 4.5577e-01,  4.0604e-01,  4.3919e-01,  ...,  5.7182e-01,\n",
            "            7.2103e-01,  8.0392e-01],\n",
            "          [ 4.2261e-01,  3.7288e-01,  3.0656e-01,  ...,  6.5472e-01,\n",
            "            7.7077e-01,  7.5419e-01]],\n",
            "\n",
            "         [[ 5.2022e-01,  8.1361e-01,  9.1716e-01,  ...,  8.1361e-01,\n",
            "            7.6183e-01,  8.4812e-01],\n",
            "          [ 5.7199e-01,  7.6183e-01,  8.4812e-01,  ...,  6.7554e-01,\n",
            "            6.4102e-01,  7.4457e-01],\n",
            "          [ 6.0651e-01,  6.2377e-01,  7.7909e-01,  ...,  8.4812e-01,\n",
            "            8.9990e-01,  1.0552e+00],\n",
            "          ...,\n",
            "          [ 8.4812e-01,  7.2732e-01,  7.1006e-01,  ...,  9.3442e-01,\n",
            "            1.0380e+00,  9.6893e-01],\n",
            "          [ 7.2732e-01,  6.7554e-01,  7.1006e-01,  ...,  8.4812e-01,\n",
            "            1.0034e+00,  1.0897e+00],\n",
            "          [ 6.7554e-01,  6.4102e-01,  5.7199e-01,  ...,  9.1716e-01,\n",
            "            1.0552e+00,  1.0380e+00]]],\n",
            "\n",
            "\n",
            "        [[[-1.4092e+00, -1.0343e+00, -6.7510e-01,  ..., -1.7371e+00,\n",
            "           -1.7215e+00, -1.7528e+00],\n",
            "          [-1.2842e+00, -1.0031e+00, -7.3757e-01,  ..., -1.7528e+00,\n",
            "           -1.7371e+00, -1.7371e+00],\n",
            "          [-1.1593e+00, -9.8746e-01, -8.4690e-01,  ..., -1.7371e+00,\n",
            "           -1.7215e+00, -1.7215e+00],\n",
            "          ...,\n",
            "          [-8.1605e-02, -1.2846e-01, -1.4408e-01,  ..., -3.5137e-03,\n",
            "            1.9952e-01,  9.0195e-02],\n",
            "          [-8.1605e-02, -9.7223e-02, -6.5986e-02,  ..., -9.7223e-02,\n",
            "           -3.4750e-02, -3.5137e-03],\n",
            "          [-6.5986e-02,  1.2104e-02,  1.3705e-01,  ..., -1.4408e-01,\n",
            "           -1.4408e-01, -1.2846e-01]],\n",
            "\n",
            "         [[-1.4508e+00, -1.1192e+00, -7.7105e-01,  ..., -1.6829e+00,\n",
            "           -1.6829e+00, -1.7160e+00],\n",
            "          [-1.4176e+00, -1.1689e+00, -9.0368e-01,  ..., -1.6995e+00,\n",
            "           -1.6829e+00, -1.6829e+00],\n",
            "          [-1.3016e+00, -1.1689e+00, -1.0197e+00,  ..., -1.7160e+00,\n",
            "           -1.6995e+00, -1.6995e+00],\n",
            "          ...,\n",
            "          [-2.5010e-02, -7.4746e-02, -9.1324e-02,  ...,  8.1476e-03,\n",
            "            2.0709e-01,  1.0762e-01],\n",
            "          [-2.5010e-02, -4.1588e-02,  8.1476e-03,  ..., -1.0790e-01,\n",
            "           -5.8167e-02, -2.5010e-02],\n",
            "          [ 8.1476e-03,  9.1041e-02,  2.2367e-01,  ..., -1.9080e-01,\n",
            "           -2.0737e-01, -2.0737e-01]],\n",
            "\n",
            "         [[-1.4300e+00, -9.6400e-01, -6.3609e-01,  ..., -1.5680e+00,\n",
            "           -1.5680e+00, -1.6026e+00],\n",
            "          [-1.2747e+00, -1.0330e+00, -8.6045e-01,  ..., -1.5680e+00,\n",
            "           -1.5508e+00, -1.5508e+00],\n",
            "          [-1.1193e+00, -1.1538e+00, -1.1711e+00,  ..., -1.6198e+00,\n",
            "           -1.6026e+00, -1.6026e+00],\n",
            "          ...,\n",
            "          [ 5.4241e-02,  2.4659e-03, -1.4792e-02,  ...,  1.0602e-01,\n",
            "            3.1312e-01,  1.9231e-01],\n",
            "          [ 3.6983e-02,  3.6983e-02,  7.1499e-02,  ..., -8.3826e-02,\n",
            "           -1.4792e-02,  1.9724e-02],\n",
            "          [ 3.6983e-02,  1.2327e-01,  2.6134e-01,  ..., -2.2189e-01,\n",
            "           -2.2189e-01, -1.8738e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.1588e-01, -2.5340e-01, -2.8464e-01,  ...,  2.0269e+00,\n",
            "            2.0269e+00,  2.0269e+00],\n",
            "          [-3.3150e-01, -2.8464e-01, -3.3150e-01,  ...,  2.0269e+00,\n",
            "            2.0269e+00,  2.0269e+00],\n",
            "          [-3.9397e-01, -3.4711e-01, -4.0959e-01,  ...,  2.0269e+00,\n",
            "            2.0269e+00,  2.0269e+00],\n",
            "          ...,\n",
            "          [ 1.1991e+00,  1.1522e+00,  9.4920e-01,  ...,  1.1679e+00,\n",
            "            1.1522e+00,  1.1522e+00],\n",
            "          [ 1.0585e+00,  1.0741e+00,  9.6481e-01,  ...,  1.1522e+00,\n",
            "            1.1210e+00,  1.1054e+00],\n",
            "          [ 1.0117e+00,  1.0741e+00,  1.1366e+00,  ...,  1.1522e+00,\n",
            "            1.1522e+00,  1.1366e+00]],\n",
            "\n",
            "         [[-2.0737e-01, -1.5764e-01, -1.7422e-01,  ...,  2.2794e+00,\n",
            "            2.2794e+00,  2.2794e+00],\n",
            "          [-2.0737e-01, -1.5764e-01, -2.0737e-01,  ...,  2.2794e+00,\n",
            "            2.2794e+00,  2.2794e+00],\n",
            "          [-2.2395e-01, -1.9080e-01, -2.4053e-01,  ...,  2.2794e+00,\n",
            "            2.2794e+00,  2.2794e+00],\n",
            "          ...,\n",
            "          [ 1.4008e+00,  1.3510e+00,  1.1189e+00,  ...,  1.3676e+00,\n",
            "            1.3510e+00,  1.3344e+00],\n",
            "          [ 1.2350e+00,  1.2515e+00,  1.1189e+00,  ...,  1.3344e+00,\n",
            "            1.3013e+00,  1.2847e+00],\n",
            "          [ 1.1852e+00,  1.2515e+00,  1.3179e+00,  ...,  1.3344e+00,\n",
            "            1.3344e+00,  1.3179e+00]],\n",
            "\n",
            "         [[ 2.0957e-01,  2.7860e-01,  2.2682e-01,  ...,  2.6602e+00,\n",
            "            2.6602e+00,  2.6602e+00],\n",
            "          [ 2.0957e-01,  2.6134e-01,  1.7505e-01,  ...,  2.6602e+00,\n",
            "            2.6602e+00,  2.6602e+00],\n",
            "          [ 1.5779e-01,  2.0957e-01,  1.4053e-01,  ...,  2.6602e+00,\n",
            "            2.6602e+00,  2.6602e+00],\n",
            "          ...,\n",
            "          [ 1.6765e+00,  1.6075e+00,  1.3486e+00,  ...,  1.6938e+00,\n",
            "            1.6765e+00,  1.6247e+00],\n",
            "          [ 1.5039e+00,  1.5212e+00,  1.3831e+00,  ...,  1.6247e+00,\n",
            "            1.6075e+00,  1.5902e+00],\n",
            "          [ 1.4867e+00,  1.5557e+00,  1.6075e+00,  ...,  1.6420e+00,\n",
            "            1.6420e+00,  1.6247e+00]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.7613e+00,  1.8082e+00,  1.8863e+00,  ...,  2.0269e+00,\n",
            "            2.0269e+00,  2.0269e+00],\n",
            "          [ 1.7457e+00,  1.8082e+00,  1.8707e+00,  ...,  2.0112e+00,\n",
            "            1.9956e+00,  1.9800e+00],\n",
            "          [ 1.8394e+00,  1.8707e+00,  1.9019e+00,  ...,  1.9331e+00,\n",
            "            1.8863e+00,  1.8707e+00],\n",
            "          ...,\n",
            "          [ 1.5271e+00,  1.4958e+00,  1.3240e+00,  ...,  1.5895e+00,\n",
            "            1.7613e+00,  1.8863e+00],\n",
            "          [ 1.5583e+00,  1.4958e+00,  1.2772e+00,  ...,  1.6833e+00,\n",
            "            1.8707e+00,  1.8707e+00],\n",
            "          [ 1.2616e+00,  1.5583e+00,  1.8863e+00,  ...,  1.4177e+00,\n",
            "            1.5427e+00,  1.6520e+00]],\n",
            "\n",
            "         [[ 1.9976e+00,  2.0307e+00,  2.0805e+00,  ...,  2.2794e+00,\n",
            "            2.2794e+00,  2.2628e+00],\n",
            "          [ 1.9810e+00,  2.0307e+00,  2.0639e+00,  ...,  2.2628e+00,\n",
            "            2.2628e+00,  2.2463e+00],\n",
            "          [ 2.0639e+00,  2.0805e+00,  2.0971e+00,  ...,  2.1965e+00,\n",
            "            2.1800e+00,  2.2131e+00],\n",
            "          ...,\n",
            "          [ 1.4836e+00,  1.4173e+00,  1.1521e+00,  ...,  1.6329e+00,\n",
            "            1.8815e+00,  2.0639e+00],\n",
            "          [ 1.6329e+00,  1.4173e+00,  1.0692e+00,  ...,  1.6826e+00,\n",
            "            1.9976e+00,  2.0639e+00],\n",
            "          [ 1.3842e+00,  1.5831e+00,  1.7986e+00,  ...,  1.1852e+00,\n",
            "            1.4008e+00,  1.6163e+00]],\n",
            "\n",
            "         [[ 2.4359e+00,  2.4877e+00,  2.5394e+00,  ...,  2.2806e+00,\n",
            "            2.2633e+00,  2.3151e+00],\n",
            "          [ 2.4186e+00,  2.4877e+00,  2.5394e+00,  ...,  2.2806e+00,\n",
            "            2.2460e+00,  2.2978e+00],\n",
            "          [ 2.5222e+00,  2.5394e+00,  2.5740e+00,  ...,  2.3841e+00,\n",
            "            2.3496e+00,  2.4186e+00],\n",
            "          ...,\n",
            "          [ 1.7628e+00,  1.5557e+00,  1.1588e+00,  ...,  1.4522e+00,\n",
            "            1.5902e+00,  1.7628e+00],\n",
            "          [ 1.6938e+00,  1.2623e+00,  7.2732e-01,  ...,  1.2968e+00,\n",
            "            1.6247e+00,  1.7973e+00],\n",
            "          [ 1.3831e+00,  1.3486e+00,  1.3659e+00,  ...,  1.0552e+00,\n",
            "            1.2968e+00,  1.6247e+00]]],\n",
            "\n",
            "\n",
            "        [[[-6.5986e-02, -1.1284e-01, -1.5970e-01,  ..., -7.3757e-01,\n",
            "           -7.5319e-01, -7.8442e-01],\n",
            "          [-5.0368e-02, -1.2846e-01, -1.5970e-01,  ..., -7.0633e-01,\n",
            "           -8.0004e-01, -7.5319e-01],\n",
            "          [-1.4408e-01, -2.2217e-01, -2.3779e-01,  ..., -4.2520e-01,\n",
            "           -8.6251e-01, -8.1566e-01],\n",
            "          ...,\n",
            "          [ 1.9956e+00,  1.9956e+00,  2.0269e+00,  ..., -1.3779e+00,\n",
            "           -1.4716e+00, -1.4092e+00],\n",
            "          [ 2.0112e+00,  1.9800e+00,  2.0112e+00,  ..., -1.4716e+00,\n",
            "           -1.4092e+00, -1.4092e+00],\n",
            "          [ 2.0112e+00,  1.9800e+00,  1.8238e+00,  ..., -1.5185e+00,\n",
            "           -1.3779e+00, -1.3154e+00]],\n",
            "\n",
            "         [[ 5.7884e-02,  8.1476e-03, -4.1588e-02,  ..., -6.5500e-01,\n",
            "           -6.7158e-01, -7.0473e-01],\n",
            "          [ 7.4462e-02, -8.4310e-03, -4.1588e-02,  ..., -5.7211e-01,\n",
            "           -7.2131e-01, -6.7158e-01],\n",
            "          [-2.5010e-02, -1.0790e-01, -1.2448e-01,  ..., -2.4053e-01,\n",
            "           -7.8763e-01, -7.3789e-01],\n",
            "          ...,\n",
            "          [ 2.2463e+00,  2.2463e+00,  2.2794e+00,  ..., -1.3347e+00,\n",
            "           -1.4342e+00, -1.3679e+00],\n",
            "          [ 2.2628e+00,  2.2297e+00,  2.2628e+00,  ..., -1.4342e+00,\n",
            "           -1.3679e+00, -1.3679e+00],\n",
            "          [ 2.2628e+00,  2.2297e+00,  2.0639e+00,  ..., -1.4839e+00,\n",
            "           -1.3347e+00, -1.2684e+00]],\n",
            "\n",
            "         [[ 3.4763e-01,  2.9586e-01,  2.4408e-01,  ..., -4.1173e-01,\n",
            "           -4.1173e-01, -4.4625e-01],\n",
            "          [ 3.6489e-01,  2.7860e-01,  2.4408e-01,  ..., -2.7367e-01,\n",
            "           -4.6351e-01, -4.1173e-01],\n",
            "          [ 2.6134e-01,  1.7505e-01,  1.5779e-01,  ...,  1.0602e-01,\n",
            "           -5.4980e-01, -4.8077e-01],\n",
            "          ...,\n",
            "          [ 2.6257e+00,  2.6257e+00,  2.6602e+00,  ..., -1.1021e+00,\n",
            "           -1.2056e+00, -1.1366e+00],\n",
            "          [ 2.6430e+00,  2.6085e+00,  2.6430e+00,  ..., -1.2056e+00,\n",
            "           -1.1366e+00, -1.1366e+00],\n",
            "          [ 2.6430e+00,  2.6085e+00,  2.4359e+00,  ..., -1.2574e+00,\n",
            "           -1.1021e+00, -1.0330e+00]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0112e+00,  1.9956e+00,  1.9956e+00,  ...,  1.9644e+00,\n",
            "            1.9800e+00,  1.9956e+00],\n",
            "          [ 1.9488e+00,  1.9488e+00,  1.9644e+00,  ...,  1.9331e+00,\n",
            "            1.9488e+00,  1.9644e+00],\n",
            "          [ 1.9331e+00,  1.9488e+00,  1.9644e+00,  ...,  1.9488e+00,\n",
            "            1.9956e+00,  1.9956e+00],\n",
            "          ...,\n",
            "          [-1.6278e+00, -1.7059e+00, -1.7215e+00,  ...,  1.7770e+00,\n",
            "            1.9644e+00,  1.1835e+00],\n",
            "          [-1.7215e+00, -1.7371e+00, -1.7215e+00,  ...,  1.8551e+00,\n",
            "            1.9644e+00,  1.8707e+00],\n",
            "          [-1.7215e+00, -1.7371e+00, -1.7215e+00,  ...,  1.6052e+00,\n",
            "            1.7613e+00,  1.7770e+00]],\n",
            "\n",
            "         [[ 1.6494e+00,  1.6163e+00,  1.6329e+00,  ...,  1.7157e+00,\n",
            "            1.7323e+00,  1.7489e+00],\n",
            "          [ 1.5831e+00,  1.5831e+00,  1.5997e+00,  ...,  1.6826e+00,\n",
            "            1.6992e+00,  1.7157e+00],\n",
            "          [ 1.5665e+00,  1.5831e+00,  1.5997e+00,  ...,  1.6992e+00,\n",
            "            1.7489e+00,  1.7489e+00],\n",
            "          ...,\n",
            "          [-1.5834e+00, -1.7160e+00, -1.7492e+00,  ...,  1.4505e+00,\n",
            "            1.8152e+00,  1.0858e+00],\n",
            "          [-1.6995e+00, -1.7326e+00, -1.7658e+00,  ...,  1.5997e+00,\n",
            "            1.9313e+00,  1.9976e+00],\n",
            "          [-1.6995e+00, -1.7492e+00, -1.7658e+00,  ...,  1.0858e+00,\n",
            "            1.4339e+00,  1.5831e+00]],\n",
            "\n",
            "         [[ 7.7909e-01,  7.6183e-01,  7.6183e-01,  ...,  9.8619e-01,\n",
            "            1.0034e+00,  1.0207e+00],\n",
            "          [ 7.2732e-01,  7.2732e-01,  7.4457e-01,  ...,  9.6893e-01,\n",
            "            1.0034e+00,  1.0034e+00],\n",
            "          [ 7.1006e-01,  7.2732e-01,  7.4457e-01,  ...,  9.8619e-01,\n",
            "            1.0380e+00,  1.0380e+00],\n",
            "          ...,\n",
            "          [-1.3437e+00, -1.4645e+00, -1.5163e+00,  ...,  7.6183e-01,\n",
            "            1.3659e+00,  7.9635e-01],\n",
            "          [-1.4818e+00, -1.5163e+00, -1.5335e+00,  ...,  1.1760e+00,\n",
            "            1.6938e+00,  1.8664e+00],\n",
            "          [-1.4818e+00, -1.5163e+00, -1.5335e+00,  ...,  6.7554e-01,\n",
            "            1.1070e+00,  1.3314e+00]]]], grad_fn=<NativeBatchNormBackward0>)\n"
          ]
        }
      ],
      "source": [
        "print(output_BN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKa3BdDeFO-F"
      },
      "source": [
        "### Dropout\n",
        "\n",
        "Another technique to train deep learning models is dropout.\n",
        "\n",
        "Conceptually, dropout approximates training a large number of neural networks with different architectures in parallel.\n",
        "\n",
        "> In practice, during training, some number of layer outputs are randomly ignored (dropped out) with probability $p$.\n",
        "\n",
        "Thus, the same layer will alter its connectivity and will search for alternative paths to convey the information in the next layer. As a result, each update to a layer during training is performed with a different “view” of the configured layer.\n",
        "\n",
        "“Dropping” values means temporarily removing them from the network for the current forward pass along with all its incoming and outgoing connections.\n",
        "\n",
        "Dropout has the effect of making the training process noisy. The choice of the probability $p$ depends on the architecture.\n",
        "\n",
        "![pic](https://raw.githubusercontent.com/CUTe-EmbeddedAI/images/main/images/fig27.PNG)\n",
        "This conceptualization suggests that perhaps dropout breaks-up situations where network layers co-adapt to correct mistakes from prior layers, in turn making the model more robust.\n",
        "\n",
        "The neural network will adapt in a way that prevents overfitting, which refers to poor generalization to unseen data.\n",
        "\n",
        "Dropout increases the sparsity of the network and in general encourages sparse representations!\n",
        "\n",
        "You can find an example in the code below .\n",
        "\n",
        "Notice that each value will be zeroed with a probability of p=0.5. Nonetheless, that doesn’t imply that the output will be 50% zeroed-out every time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkEyw3pDFO-I",
        "outputId": "b64f1901-bf97-41b8-dd4d-da3eeb19e074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.6257, 0.9145, 0.6141, 0.4462, 0.6239, 0.4524, 0.5738, 0.4249]])\n",
            "tensor([[0.0000, 1.8291, 1.2281, 0.8925, 0.0000, 0.0000, 0.0000, 0.8498]])\n",
            "tensor([[1.2514, 0.0000, 1.2281, 0.8925, 1.2477, 0.0000, 1.1475, 0.0000]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "inp = torch.rand(1,8) \n",
        "dropout_layer = nn.Dropout(0.5)\n",
        "out1 = dropout_layer(inp)\n",
        "out2 = dropout_layer(inp)\n",
        "print(inp)\n",
        "print(out1)\n",
        "print(out2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2vah6ZTFO-L"
      },
      "source": [
        "### Training with batchnorm\n",
        "\n",
        "Now, it's the time to apply batchnorm and dropout! Let's copy and paste the code for training a CNN in our previous notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhztnMavFO-X"
      },
      "source": [
        "Here, try to incorporate batchnorm as a layer in this vanilla CNN.\n",
        "\n",
        "Note that in pytorch, batchnorm can be implemented using `nn.BatchNorm2d(num_features)` for 2D input and `nn.BatchNorm2d(num_features)` for 1D input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLDK3OpMFO-k"
      },
      "source": [
        "### Training with dropout\n",
        "\n",
        "Adding dropout to your PyTorch models is very straightforward with the `torch.nn.Dropout` class, which takes in the dropout rate – the probability of a neuron being deactivated – as a parameter.\n",
        "\n",
        "Go back to the CNN class and try to incorporate dropout as an additional layer in the fully connected layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aocAQZf_FO-Z"
      },
      "outputs": [],
      "source": [
        "#1. DEFINE THE CNN WITH BATCHNORM\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(6) # defining our batchnorm1 layer\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(16) # defining our batchnorm2 layer\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        # INCLUDE BATCHNORM IN THE FORWARD METHOD #\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        # INCLUDE BATCHNORM IN THE FORWARD METHOD #\n",
        "        x = self.batchnorm2(x)\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgWT1BGZFO-b",
        "outputId": "79d50119-36d0-4b27-d61d-dee86efa9e86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (batchnorm1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (batchnorm2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (relu): ReLU()\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = CNN() # need to instantiate the network to be used in instance method\n",
        "\n",
        "# LOSS AND OPTIMIZER\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# move the model to GPU\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iqUb-WREFO-e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Train in one epoch function\n",
        "def train_one_epoch(model, train_loader, loss_fn, optimizer, device):\n",
        "    model.train()\n",
        "    train_loss, train_correct = 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        _, predictions = torch.max(outputs, 1)\n",
        "        train_correct += torch.sum(predictions == labels.data)\n",
        "\n",
        "    return train_loss / len(train_loader.dataset), train_correct.double() / len(train_loader.dataset)\n",
        "\n",
        "# Validation function\n",
        "def validate(model, val_loader, loss_fn, device):\n",
        "    model.eval()\n",
        "    val_loss, val_correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            val_correct += torch.sum(predictions == labels.data)\n",
        "\n",
        "    return val_loss / len(val_loader.dataset), val_correct.double() / len(val_loader.dataset)\n",
        "\n",
        "# Training and validation loop with timing\n",
        "def train_and_validate(model, train_loader, val_loader, loss_fn, optimizer, epochs, device='cuda'):\n",
        "    model.to(device)\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_accuracy': [],\n",
        "        'val_loss': [],\n",
        "        'val_accuracy': []\n",
        "    }\n",
        "\n",
        "    for epoch in tqdm(range(epochs), desc=\"Training Progress\", leave=True):\n",
        "        epoch_start_time = time.time()\n",
        "\n",
        "        train_loss, train_accuracy = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\n",
        "        val_loss, val_accuracy = validate(model, val_loader, loss_fn, device)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_accuracy'].append(train_accuracy.item())\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_accuracy'].append(val_accuracy.item())\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "\n",
        "        # Use tqdm.write() instead of print() to avoid extra blank lines\n",
        "        tqdm.write(f'Epoch {epoch+1}/{epochs}: Train loss: {train_loss:.4f}, Train accuracy: {train_accuracy:.4f}, '\n",
        "                   f'Val loss: {val_loss:.4f}, Val accuracy: {val_accuracy:.4f}, '\n",
        "                   f'Time: {(epoch_end_time - epoch_start_time):.2f}s')\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "13583170358c4c0da03ab7252553976e",
            "e50ba2d39a374e9096c112ad4798e3f5",
            "316e81bafbb64beb8db9d30f37a2ec03",
            "8aaf4e25d45842b58dc62d1c7ee68d69",
            "5518e78b3c1248cdbca2ccaee224ad63",
            "7b7efc4cb753414185b700dddd363d11",
            "6744fd744e084633ac5a93bd05ab0037",
            "85b5bc6751764beab6689e6dcdaec549",
            "d5936b8de2f54622a0a8512418647923",
            "786a4ea44f7340b988d9c94323e62a38",
            "683b8cc4e9bf43cdb43595ffb3746db1"
          ]
        },
        "id": "ngaHvvWZFO-i",
        "outputId": "336f971f-152e-4992-9b2f-bcf363574021"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  10%|█         | 1/10 [00:49<07:24, 49.37s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: Train loss: 1.6419, Train accuracy: 0.4042, Val loss: 1.3480, Val accuracy: 0.5109, Time: 49.37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  20%|██        | 2/10 [01:38<06:34, 49.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: Train loss: 1.2856, Train accuracy: 0.5387, Val loss: 1.2159, Val accuracy: 0.5597, Time: 49.25s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  30%|███       | 3/10 [02:28<05:45, 49.42s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: Train loss: 1.1529, Train accuracy: 0.5892, Val loss: 1.1280, Val accuracy: 0.5969, Time: 49.55s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  40%|████      | 4/10 [03:15<04:52, 48.74s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: Train loss: 1.0627, Train accuracy: 0.6227, Val loss: 1.0609, Val accuracy: 0.6276, Time: 47.71s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  50%|█████     | 5/10 [04:03<04:01, 48.32s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: Train loss: 0.9986, Train accuracy: 0.6455, Val loss: 1.0270, Val accuracy: 0.6368, Time: 47.57s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  60%|██████    | 6/10 [04:52<03:14, 48.66s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: Train loss: 0.9458, Train accuracy: 0.6654, Val loss: 1.0165, Val accuracy: 0.6468, Time: 49.31s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  70%|███████   | 7/10 [05:41<02:25, 48.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: Train loss: 0.8987, Train accuracy: 0.6845, Val loss: 0.9815, Val accuracy: 0.6572, Time: 48.43s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  80%|████████  | 8/10 [06:29<01:37, 48.62s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: Train loss: 0.8616, Train accuracy: 0.6969, Val loss: 0.9918, Val accuracy: 0.6539, Time: 48.70s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training Progress:  80%|████████  | 8/10 [06:45<01:41, 50.67s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m----> 2\u001b[0m trained_model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[11], line 54\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(model, train_loader, val_loader, loss_fn, optimizer, epochs, device)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Progress\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     52\u001b[0m     epoch_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 54\u001b[0m     train_loss, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m validate(model, val_loader, loss_fn, device)\n\u001b[0;32m     57\u001b[0m     history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
            "Cell \u001b[1;32mIn[11], line 9\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, train_loader, loss_fn, optimizer, device)\u001b[0m\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      7\u001b[0m train_loss, train_correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     10\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[2], line 9\u001b[0m, in \u001b[0;36mCIFAR10Dataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torchvision\\datasets\\cifar.py:119\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    116\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    122\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torchvision\\transforms\\functional.py:350\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\IIUM\\AI Note IIUM\\venv\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:922\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    920\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    921\u001b[0m std \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(std, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd evaluated to zero after conversion to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, leading to division by zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mean\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epochs =10\n",
        "trained_model, history = train_and_validate(model, train_dataloader, test_dataloader, loss_fn, optimizer, num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "wN477QQ4e6h-",
        "outputId": "1f855187-0a81-4775-8dbc-cf7f107d4012"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAHqCAYAAADVi/1VAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAhLtJREFUeJzs3Xd8U/X+x/F3kjbpLmW1bBBQ9h4CV0BFKyjX4gJUlqA/vaAiclUUEXDUhaKi4GC4EMUrOEARqzgQBcQiKKIoUEXKprtpm5zfH2lD06Z0UJKWvp6PRx4553tGPkkLfHnne77HZBiGIQAAAAAAAMCHzP4uAAAAAAAAADUPoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUUE2MHTtWzZs3r9CxM2fOlMlkqtyCqpg9e/bIZDJpyZIlPn9tk8mkmTNnuteXLFkik8mkPXv2lHps8+bNNXbs2Eqt51R+VwAA8Df6PCdHn+cE+jxA9UcoBZwik8lUpse6dev8XWqNd9ttt8lkMmnXrl0l7nPffffJZDLpp59+8mFl5ffPP/9o5syZSkxM9HcpbgWd5CeffNLfpQAATgP6PNUHfR7f2bFjh0wmk4KCgnT8+HF/lwNUOwH+LgCo7l5//XWP9ddee01r164t1t62bdtTep2XX35ZTqezQsdOnz5d99xzzym9/pnguuuu03PPPaelS5dqxowZXvd566231LFjR3Xq1KnCrzNq1CiNGDFCNputwucozT///KNZs2apefPm6tKli8e2U/ldAQCgJPR5qg/6PL7zxhtvKCYmRseOHdO7776rCRMm+LUeoLohlAJO0fXXX++x/t1332nt2rXF2ovKzMxUSEhImV8nMDCwQvVJUkBAgAIC+OPeu3dvtWrVSm+99ZbXDtqGDRu0e/duPfroo6f0OhaLRRaL5ZTOcSpO5XcFAICS0OepPujz+IZhGFq6dKmuvfZa7d69W2+++WaVDaUyMjIUGhrq7zKAYrh8D/CBgQMHqkOHDvrhhx/Uv39/hYSE6N5775Ukvf/++7r00kvVsGFD2Ww2tWzZUg8++KAcDofHOYpeM1/4UqmXXnpJLVu2lM1mU8+ePbVp0yaPY73Nr2AymTRp0iStXLlSHTp0kM1mU/v27fXJJ58Uq3/dunXq0aOHgoKC1LJlS7344otlnrPh66+/1tVXX62mTZvKZrOpSZMmuuOOO5SVlVXs/YWFhWnfvn2Ki4tTWFiY6tWrp6lTpxb7LI4fP66xY8cqMjJStWrV0pgxY8o8XPq6667Tr7/+qi1bthTbtnTpUplMJo0cOVI5OTmaMWOGunfvrsjISIWGhuq8887TF198UepreJtfwTAMPfTQQ2rcuLFCQkJ0/vnn6+effy527NGjRzV16lR17NhRYWFhioiI0ODBg7V161b3PuvWrVPPnj0lSePGjXNfLlEwt4S3+RUyMjJ05513qkmTJrLZbDrnnHP05JNPyjAMj/3K83tRUQcPHtT48eMVHR2toKAgde7cWa+++mqx/ZYtW6bu3bsrPDxcERER6tixo5555hn39tzcXM2aNUutW7dWUFCQ6tSpo3/9619au3ZtpdUKACgf+jz0eWpSn2f9+vXas2ePRowYoREjRuirr77S33//XWw/p9OpZ555Rh07dlRQUJDq1aunSy65RJs3b/bY74033lCvXr0UEhKiqKgo9e/fX59++qlHzYXn9CpQdL6ugp/Ll19+qf/85z+qX7++GjduLEnau3ev/vOf/+icc85RcHCw6tSpo6uvvtrrvGDHjx/XHXfcoebNm8tms6lx48YaPXq0Dh8+rPT0dIWGhur2228vdtzff/8ti8Wi+Pj4Mn6SqMn4GgHwkSNHjmjw4MEaMWKErr/+ekVHR0ty/aMRFhamKVOmKCwsTJ9//rlmzJih1NRUPfHEE6Wed+nSpUpLS9P//d//yWQy6fHHH9cVV1yhP//8s9Rvj7755hu99957+s9//qPw8HA9++yzuvLKK5WUlKQ6depIkn788UddcsklatCggWbNmiWHw6HZs2erXr16ZXrfy5cvV2Zmpm655RbVqVNHGzdu1HPPPae///5by5cv99jX4XAoNjZWvXv31pNPPqnPPvtMc+bMUcuWLXXLLbdIcnV0Lr/8cn3zzTe6+eab1bZtW61YsUJjxowpUz3XXXedZs2apaVLl6pbt24er/3OO+/ovPPOU9OmTXX48GG98sorGjlypG688UalpaVp4cKFio2N1caNG4sNHy/NjBkz9NBDD2nIkCEaMmSItmzZoosvvlg5OTke+/35559auXKlrr76arVo0UIHDhzQiy++qAEDBuiXX35Rw4YN1bZtW82ePVszZszQTTfdpPPOO0+S1LdvX6+vbRiG/v3vf+uLL77Q+PHj1aVLF61Zs0b//e9/tW/fPj399NMe+5fl96KisrKyNHDgQO3atUuTJk1SixYttHz5co0dO1bHjx93d2zWrl2rkSNH6sILL9Rjjz0myTVnw/r16937zJw5U/Hx8ZowYYJ69eql1NRUbd68WVu2bNFFF110SnUCACqOPg99nprS53nzzTfVsmVL9ezZUx06dFBISIjeeust/fe///XYb/z48VqyZIkGDx6sCRMmKC8vT19//bW+++479ejRQ5I0a9YszZw5U3379tXs2bNltVr1/fff6/PPP9fFF19c5s+/sP/85z+qV6+eZsyYoYyMDEnSpk2b9O2332rEiBFq3Lix9uzZo/nz52vgwIH65Zdf3KMa09PTdd5552nHjh264YYb1K1bNx0+fFgffPCB/v77b3Xp0kXDhg3T22+/raeeespjxNxbb70lwzB03XXXVahu1DAGgEo1ceJEo+gfrQEDBhiSjAULFhTbPzMzs1jb//3f/xkhISFGdna2u23MmDFGs2bN3Ou7d+82JBl16tQxjh496m5///33DUnGhx9+6G574IEHitUkybBarcauXbvcbVu3bjUkGc8995y7bejQoUZISIixb98+d9vvv/9uBAQEFDunN97eX3x8vGEymYy9e/d6vD9JxuzZsz327dq1q9G9e3f3+sqVKw1JxuOPP+5uy8vLM8477zxDkrF48eJSa+rZs6fRuHFjw+FwuNs++eQTQ5Lx4osvus9pt9s9jjt27JgRHR1t3HDDDR7tkowHHnjAvb548WJDkrF7927DMAzj4MGDhtVqNS699FLD6XS697v33nsNScaYMWPcbdnZ2R51GYbrZ22z2Tw+m02bNpX4fov+rhR8Zg899JDHfldddZVhMpk8fgfK+nvhTcHv5BNPPFHiPnPnzjUkGW+88Ya7LScnx+jTp48RFhZmpKamGoZhGLfffrsRERFh5OXllXiuzp07G5deeulJawIAnD70eUp/f/R5XM60Po9huPovderUMe677z5327XXXmt07tzZY7/PP//ckGTcdtttxc5R8Bn9/vvvhtlsNoYNG1bsMyn8ORb9/As0a9bM47Mt+Ln861//KtaX8vZ7umHDBkOS8dprr7nbZsyYYUgy3nvvvRLrXrNmjSHJ+Pjjjz22d+rUyRgwYECx4wBvuHwP8BGbzaZx48YVaw8ODnYvp6Wl6fDhwzrvvPOUmZmpX3/9tdTzDh8+XFFRUe71gm+Q/vzzz1KPHTRokFq2bOle79SpkyIiItzHOhwOffbZZ4qLi1PDhg3d+7Vq1UqDBw8u9fyS5/vLyMjQ4cOH1bdvXxmGoR9//LHY/jfffLPH+nnnnefxXlavXq2AgAD3t4iSaz6DW2+9tUz1SK45Mf7++2999dVX7ralS5fKarXq6quvdp/TarVKcg25Pnr0qPLy8tSjRw+vw+BP5rPPPlNOTo5uvfVWj+H/kydPLravzWaT2ez6q9nhcOjIkSMKCwvTOeecU+7XLbB69WpZLBbddtttHu133nmnDMPQxx9/7NFe2u/FqVi9erViYmI0cuRId1tgYKBuu+02paen68svv5Qk1apVSxkZGSe9FK9WrVr6+eef9fvvv59yXQCAykOfhz5PTejzfPzxxzpy5IhHn2bkyJHaunWrx+WK//vf/2QymfTAAw8UO0fBZ7Ry5Uo5nU7NmDHD/ZkU3acibrzxxmJzfhX+Pc3NzdWRI0fUqlUr1apVy+Nz/9///qfOnTtr2LBhJdY9aNAgNWzYUG+++aZ72/bt2/XTTz+VOtccUIBQCvCRRo0auf/BL+znn3/WsGHDFBkZqYiICNWrV8/9l3hKSkqp523atKnHekFn7dixY+U+tuD4gmMPHjyorKwstWrVqth+3tq8SUpK0tixY1W7dm33nAkDBgyQVPz9FVxjX1I9kus6+AYNGigsLMxjv3POOadM9UjSiBEjZLFYtHTpUklSdna2VqxYocGDB3t0dl999VV16tTJPV9RvXr1tGrVqjL9XArbu3evJKl169Ye7fXq1fN4PcnVGXz66afVunVr2Ww21a1bV/Xq1dNPP/1U7tct/PoNGzZUeHi4R3vB3ZEK6itQ2u/Fqdi7d69at25drMNVtJb//Oc/OvvsszV48GA1btxYN9xwQ7E5HmbPnq3jx4/r7LPPVseOHfXf//63yt/WGgBqAvo89HlqQp/njTfeUIsWLWSz2bRr1y7t2rVLLVu2VEhIiEdI88cff6hhw4aqXbt2ief6448/ZDab1a5du1JftzxatGhRrC0rK0szZsxwz7lV8LkfP37c43P/448/1KFDh5Oe32w267rrrtPKlSuVmZkpyXVJY1BQkDv0BEpDKAX4SOFvJQocP35cAwYM0NatWzV79mx9+OGHWrt2rXsOnbLc4rakO54YRSZzrOxjy8LhcOiiiy7SqlWrdPfdd2vlypVau3ate3LKou/PV3dvqV+/vi666CL973//U25urj788EOlpaV5XPf+xhtvaOzYsWrZsqUWLlyoTz75RGvXrtUFF1xwWm89/Mgjj2jKlCnq37+/3njjDa1Zs0Zr165V+/btfXbL49P9e1EW9evXV2Jioj744AP33BCDBw/2mEejf//++uOPP7Ro0SJ16NBBr7zyirp166ZXXnnFZ3UCAIqjz0Ofpyyqc58nNTVVH374oXbv3q3WrVu7H+3atVNmZqaWLl3q035T0QnyC3j7s3jrrbfq4Ycf1jXXXKN33nlHn376qdauXas6depU6HMfPXq00tPTtXLlSvfdCC+77DJFRkaW+1yomZjoHPCjdevW6ciRI3rvvffUv39/d/vu3bv9WNUJ9evXV1BQkHbt2lVsm7e2orZt26bffvtNr776qkaPHu1uP5W7ozVr1kwJCQlKT0/3+OZw586d5TrPddddp08++UQff/yxli5dqoiICA0dOtS9/d1339VZZ52l9957z2PYtLeh12WpWZJ+//13nXXWWe72Q4cOFfsm7t1339X555+vhQsXerQfP35cdevWda+XZyh3s2bN9NlnnyktLc3jm8OCSyUK6vOFZs2a6aeffpLT6fQYLeWtFqvVqqFDh2ro0KFyOp36z3/+oxdffFH333+/+1vr2rVra9y4cRo3bpzS09PVv39/zZw5s8rejhkAair6POVHn8elKvZ53nvvPWVnZ2v+/PketUqun8/06dO1fv16/etf/1LLli21Zs0aHT16tMTRUi1btpTT6dQvv/xy0onlo6Kiit19MScnR/v37y9z7e+++67GjBmjOXPmuNuys7OLnbdly5bavn17qefr0KGDunbtqjfffFONGzdWUlKSnnvuuTLXAzBSCvCjgm9nCn+TkpOToxdeeMFfJXmwWCwaNGiQVq5cqX/++cfdvmvXrmLX5Jd0vOT5/gzD0DPPPFPhmoYMGaK8vDzNnz/f3eZwOMr9j19cXJxCQkL0wgsv6OOPP9YVV1yhoKCgk9b+/fffa8OGDeWuedCgQQoMDNRzzz3ncb65c+cW29disRT7Zm358uXat2+fR1toaKgklem20EOGDJHD4dC8efM82p9++mmZTKYyz5VRGYYMGaLk5GS9/fbb7ra8vDw999xzCgsLc1/mcOTIEY/jzGazOnXqJEmy2+1e9wkLC1OrVq3c2wEAVQd9nvKjz+NSFfs8b7zxhs466yzdfPPNuuqqqzweU6dOVVhYmPsSviuvvFKGYWjWrFnFzlPw/uPi4mQ2mzV79uxio5UKf0YtW7b0mB9Mkl566aUSR0p54+1zf+6554qd48orr9TWrVu1YsWKEusuMGrUKH366aeaO3eu6tSp49O+Jao/RkoBftS3b19FRUVpzJgxuu2222QymfT666/7dLhvaWbOnKlPP/1U/fr10y233OL+h75Dhw5KTEw86bFt2rRRy5YtNXXqVO3bt08RERH63//+d0pzEw0dOlT9+vXTPffcoz179qhdu3Z67733yj33QFhYmOLi4txzLBS9Ze1ll12m9957T8OGDdOll16q3bt3a8GCBWrXrp3S09PL9Vr16tXT1KlTFR8fr8suu0xDhgzRjz/+qI8//rjYt2uXXXaZZs+erXHjxqlv377atm2b3nzzTY9vGyVXp6RWrVpasGCBwsPDFRoaqt69e3udO2Do0KE6//zzdd9992nPnj3q3LmzPv30U73//vuaPHmyxwSflSEhIUHZ2dnF2uPi4nTTTTfpxRdf1NixY/XDDz+oefPmevfdd7V+/XrNnTvX/a3mhAkTdPToUV1wwQVq3Lix9u7dq+eee05dunRxzwvRrl07DRw4UN27d1ft2rW1efNmvfvuu5o0aVKlvh8AwKmjz1N+9Hlcqlqf559//tEXX3xRbDL1AjabTbGxsVq+fLmeffZZnX/++Ro1apSeffZZ/f7777rkkkvkdDr19ddf6/zzz9ekSZPUqlUr3XfffXrwwQd13nnn6YorrpDNZtOmTZvUsGFDxcfHS3L1j26++WZdeeWVuuiii7R161atWbOm2Gd7Mpdddplef/11RUZGql27dtqwYYM+++wz1alTx2O///73v3r33Xd19dVX64YbblD37t119OhRffDBB1qwYIE6d+7s3vfaa6/VXXfdpRUrVuiWW25RYGBgBT5Z1Fg+uMMfUKOUdHvk9u3be91//fr1xrnnnmsEBwcbDRs2NO666y737VW/+OIL934l3R75iSeeKHZOFbldbEm3R544cWKxY4veUtYwDCMhIcHo2rWrYbVajZYtWxqvvPKKceeddxpBQUElfAon/PLLL8agQYOMsLAwo27dusaNN97ovt1u4Vv7jhkzxggNDS12vLfajxw5YowaNcqIiIgwIiMjjVGjRhk//vhjmW+PXGDVqlWGJKNBgwZeb7/7yCOPGM2aNTNsNpvRtWtX46OPPir2czCM0m+PbBiG4XA4jFmzZhkNGjQwgoODjYEDBxrbt28v9nlnZ2cbd955p3u/fv36GRs2bDAGDBhQ7Na677//vtGuXTv3raoL3ru3GtPS0ow77rjDaNiwoREYGGi0bt3aeOKJJzxuM1zwXsr6e1FUwe9kSY/XX3/dMAzDOHDggDFu3Dijbt26htVqNTp27Fjs5/buu+8aF198sVG/fn3DarUaTZs2Nf7v//7P2L9/v3ufhx56yOjVq5dRq1YtIzg42GjTpo3x8MMPGzk5OSetEwBQOejzeKLP43Km93nmzJljSDISEhJK3GfJkiWGJOP99983DMMw8vLyjCeeeMJo06aNYbVajXr16hmDBw82fvjhB4/jFi1aZHTt2tWw2WxGVFSUMWDAAGPt2rXu7Q6Hw7j77ruNunXrGiEhIUZsbKyxa9euYjUX/Fw2bdpUrLZjx465+2FhYWFGbGys8euvv3p930eOHDEmTZpkNGrUyLBarUbjxo2NMWPGGIcPHy523iFDhhiSjG+//bbEzwXwxmQYVejrCQDVRlxcnH7++Wf9/vvv/i4FAADgtKHPA5Ru2LBh2rZtW5nmYAMKY04pAKXKysryWP/999+1evVqDRw40D8FAQAAnAb0eYDy279/v1atWqVRo0b5uxRUQ4yUAlCqBg0aaOzYsTrrrLO0d+9ezZ8/X3a7XT/++KNat27t7/IAAAAqBX0eoOx2796t9evX65VXXtGmTZv0xx9/KCYmxt9loZphonMApbrkkkv01ltvKTk5WTabTX369NEjjzxC5wwAAJxR6PMAZffll19q3Lhxatq0qV599VUCKVSIXy/fmz9/vjp16qSIiAhFRESoT58+pd5ydfny5WrTpo2CgoLUsWNHrV692kfVAjXX4sWLtWfPHmVnZyslJUWffPKJunXr5u+yAKDG+uqrrzR06FA1bNhQJpNJK1euLPWYdevWqVu3brLZbGrVqpWWLFly2usEqhv6PEDZjR07VoZhaO/evbrqqqv8XQ6qKb+GUo0bN9ajjz6qH374QZs3b9YFF1ygyy+/XD///LPX/b/99luNHDlS48eP148//qi4uDjFxcVp+/btPq4cAADAfzIyMtS5c2c9//zzZdp/9+7duvTSS3X++ecrMTFRkydP1oQJE7RmzZrTXCkAAEDJqtycUrVr19YTTzyh8ePHF9s2fPhwZWRk6KOPPnK3nXvuuerSpYsWLFjgyzIBAACqBJPJpBUrViguLq7Efe6++26tWrXK44u8ESNG6Pjx4/rkk098UCUAAEBxVWZOKYfDoeXLlysjI0N9+vTxus+GDRs0ZcoUj7bY2NiTDlm32+2y2+3udafTqaNHj6pOnToymUyVUjsAADhzFXx/FxERUW37Dhs2bNCgQYM82mJjYzV58uQSj6EPBQAAKsowDKWlpalhw4Yym0u+SM/vodS2bdvUp08fZWdnKywsTCtWrFC7du287pucnKzo6GiPtujoaCUnJ5d4/vj4eM2aNatSawYAADVPSkqKIiIi/F1GhZTUh0pNTVVWVpaCg4OLHUMfCgAAnKq//vpLjRs3LnG730Opc845R4mJiUpJSdG7776rMWPG6MsvvywxmCqvadOmeYyuSklJUdOmTfXXX39V244lAADwndTUVDVp0sTfZfgcfSgAAFBRBf2n8PDwk+7n91DKarWqVatWkqTu3btr06ZNeuaZZ/Tiiy8W2zcmJkYHDhzwaDtw4MBJbz1ps9lks9mKtRfc8Q8AAOBMV1IfKiIiwusoKYk+FAAAOHWlXfLv17vveeN0Oj3mLyisT58+SkhI8Ghbu3ZtiXNQAQAAgD4UAAComvw6UmratGkaPHiwmjZtqrS0NC1dulTr1q1z35549OjRatSokeLj4yVJt99+uwYMGKA5c+bo0ksv1bJly7R582a99NJL/nwbAAAAPpWenq5du3a513fv3q3ExETVrl1bTZs21bRp07Rv3z699tprkqSbb75Z8+bN01133aUbbrhBn3/+ud555x2tWrXKX28BAADAv6HUwYMHNXr0aO3fv1+RkZHq1KmT1qxZo4suukiSlJSU5DFLe9++fbV06VJNnz5d9957r1q3bq2VK1eqQ4cO/noLAAAAPrd582adf/757vWCuZ/GjBmjJUuWaP/+/UpKSnJvb9GihVatWqU77rhDzzzzjBo3bqxXXnlFsbGxPq8dAACggMkouM9xDZGamqrIyMhqfQcdAKipHA6HcnNz/V0GzjCBgYGyWCwlbqfv4MLnAADlR98FZ6rK6j/5faJzAABKYxiGkpOTdfz4cX+XgjNUrVq1FBMTU+pknAAAlAV9F9QEldF/IpQCAFR5BZ26+vXrKyQkhOAAlcYwDGVmZurgwYOSpAYNGvi5IgDAmYC+C85kldl/IpQCAFRpDofD3amrU6eOv8vBGSg4OFiSa67L+vXrn3QoOgAApaHvgpqgsvpP5tJ3AQDAfwrmYQgJCfFzJTiTFfx+Me8HAOBU0XdBTVEZ/SdCKQBAtcCwd5xO/H4BACob/7bgTFcZv+OEUgAAAAAAAPA5QikAAKqJ5s2ba+7cuWXef926dTKZTNz5BwAA+A39F5wMoRQAAJXMZDKd9DFz5swKnXfTpk266aabyrx/3759tX//fkVGRlbo9cqKziMAANVfTeu/FNamTRvZbDYlJyf77DXhwt33AACoZPv373cvv/3225oxY4Z27tzpbgsLC3MvG4Yhh8OhgIDS/0muV69eueqwWq2KiYkp1zEAAKBmqqn9l2+++UZZWVm66qqr9Oqrr+ruu+/22Wt7k5ubq8DAQL/W4EuMlAIAoJLFxMS4H5GRkTKZTO71X3/9VeHh4fr444/VvXt32Ww2ffPNN/rjjz90+eWXKzo6WmFhYerZs6c+++wzj/MWHf5uMpn0yiuvaNiwYQoJCVHr1q31wQcfuLcXHcG0ZMkS1apVS2vWrFHbtm0VFhamSy65xKMTmpeXp9tuu021atVSnTp1dPfdd2vMmDGKi4ur8Odx7NgxjR49WlFRUQoJCdHgwYP1+++/u7fv3btXQ4cOVVRUlEJDQ9W+fXutXr3afex1112nevXqKTg4WK1bt9bixYsrXAsAAPCupvZfFi5cqGuvvVajRo3SokWLim3/+++/NXLkSNWuXVuhoaHq0aOHvv/+e/f2Dz/8UD179lRQUJDq1q2rYcOGebzXlStXepyvVq1aWrJkiSRpz549MplMevvttzVgwAAFBQXpzTff1JEjRzRy5Eg1atRIISEh6tixo9566y2P8zidTj3++ONq1aqVbDabmjZtqocffliSdMEFF2jSpEke+x86dEhWq1UJCQmlfia+RCgFAKh2DMNQZk6ezx+GYVTae7jnnnv06KOPaseOHerUqZPS09M1ZMgQJSQk6Mcff9Qll1yioUOHKikp6aTnmTVrlq655hr99NNPGjJkiK677jodPXq0xP0zMzP15JNP6vXXX9dXX32lpKQkTZ061b39scce05tvvqnFixdr/fr1Sk1NLdaZKq+xY8dq8+bN+uCDD7RhwwYZhqEhQ4a4bx88ceJE2e12ffXVV9q2bZsee+wx97ex999/v3755Rd9/PHH2rFjh+bPn6+6deueUj0AAPiav/ou9F9OLi0tTcuXL9f111+viy66SCkpKfr666/d29PT0zVgwADt27dPH3zwgbZu3aq77rpLTqdTkrRq1SoNGzZMQ4YM0Y8//qiEhAT16tWr1Nct6p577tHtt9+uHTt2KDY2VtnZ2erevbtWrVql7du366abbtKoUaO0ceNG9zHTpk3To48+6u4rLV26VNHR0ZKkCRMmaOnSpbLb7e7933jjDTVq1EgXXHBBues7nbh8DwBQ7WTlOtRuxhqfv+4vs2MVYq2cfzpnz56tiy66yL1eu3Ztde7c2b3+4IMPasWKFfrggw+KfdNV2NixYzVy5EhJ0iOPPKJnn31WGzdu1CWXXOJ1/9zcXC1YsEAtW7aUJE2aNEmzZ892b3/uuec0bdo097d88+bNc49aqojff/9dH3zwgdavX6++fftKkt588001adJEK1eu1NVXX62kpCRdeeWV6tixoyTprLPOch+flJSkrl27qkePHpJc37YCAFDd+KvvItF/OZlly5apdevWat++vSRpxIgRWrhwoc477zxJ0tKlS3Xo0CFt2rRJtWvXliS1atXKffzDDz+sESNGaNasWe62wp9HWU2ePFlXXHGFR1vh0O3WW2/VmjVr9M4776hXr15KS0vTM888o3nz5mnMmDGSpJYtW+pf//qXJOmKK67QpEmT9P777+uaa66R5BpxNnbsWJlMpnLXdzoxUgoAAD8oCFkKpKena+rUqWrbtq1q1aqlsLAw7dixo9RvGjt16uReDg0NVUREhA4ePFji/iEhIe4OnSQ1aNDAvX9KSooOHDjg8Q2fxWJR9+7dy/XeCtuxY4cCAgLUu3dvd1udOnV0zjnnaMeOHZKk2267TQ899JD69eunBx54QD/99JN731tuuUXLli1Tly5ddNddd+nbb7+tcC0AAODUnGn9l0WLFun66693r19//fVavny50tLSJEmJiYnq2rWrO5AqKjExURdeeGGpr1Oaop+rw+HQgw8+qI4dO6p27doKCwvTmjVr3J/rjh07ZLfbS3ztoKAgj8sRt2zZou3bt2vs2LGnXGtlY6QUAKDaCQ606JfZsX553coSGhrqsT516lStXbtWTz75pFq1aqXg4GBdddVVysnJOel5ik6EaTKZ3EPKy7p/ZQ7rr4gJEyYoNjZWq1at0qeffqr4+HjNmTNHt956qwYPHqy9e/dq9erVWrt2rS688EJNnDhRTz75pF9rBgCgPPzVdyl47cpyJvVffvnlF3333XfauHGjx+TmDodDy5Yt04033qjg4OCTnqO07d7qLJi+oLCin+sTTzyhZ555RnPnzlXHjh0VGhqqyZMnuz/X0l5XcvWvunTpor///luLFy/WBRdcoGbNmpV6nK8xUgoAUO2YTCaFWAN8/jidw53Xr1+vsWPHatiwYerYsaNiYmK0Z8+e0/Z63kRGRio6OlqbNm1ytzkcDm3ZsqXC52zbtq3y8vI8JgQ9cuSIdu7cqXbt2rnbmjRpoptvvlnvvfee7rzzTr388svubfXq1dOYMWP0xhtvaO7cuXrppZcqXA8AAP7gr74L/ZeSLVy4UP3799fWrVuVmJjofkyZMkULFy6U5BrRlZiYWOJ8V506dTrpxOH16tXzmJD9999/V2ZmZqnvaf369br88st1/fXXq3PnzjrrrLP022+/ube3bt1awcHBJ33tjh07qkePHnr55Ze1dOlS3XDDDaW+rj8wUgoAgCqgdevWeu+99zR06FCZTCbdf//9J/3G8HS59dZbFR8fr1atWqlNmzZ67rnndOzYsTJ1aLdt26bw8HD3uslkUufOnXX55Zfrxhtv1Isvvqjw8HDdc889atSokS6//HJJrnkUBg8erLPPPlvHjh3TF198obZt20qSZsyYoe7du6t9+/ay2+366KOP3NsAAIB/Vdf+S25url5//XXNnj1bHTp08Ng2YcIEPfXUU/r55581cuRIPfLII4qLi1N8fLwaNGigH3/8UQ0bNlSfPn30wAMP6MILL1TLli01YsQI5eXlafXq1e6RVxdccIHmzZunPn36yOFw6O677y426sub1q1b691339W3336rqKgoPfXUUzpw4ID7C72goCDdfffduuuuu2S1WtWvXz8dOnRIP//8s8aPH+/xXiZNmqTQ0FCPuwJWJYyUAgCgCnjqqacUFRWlvn37aujQoYqNjVW3bt18Xsfdd9+tkSNHavTo0erTp4/CwsIUGxuroKCgUo/t37+/unbt6n4UzOWwePFide/eXZdddpn69OkjwzC0evVqd6fM4XBo4sSJatu2rS655BKdffbZeuGFFyRJVqtV06ZNU6dOndS/f39ZLBYtW7bs9H0AAACgzKpr/+WDDz7QkSNHvAY1bdu2Vdu2bbVw4UJZrVZ9+umnql+/voYMGaKOHTvq0UcflcXiuiRy4MCBWr58uT744AN16dJFF1xwgccd8ubMmaMmTZrovPPO07XXXqupU6cqJCSk1Pczffp0devWTbGxsRo4cKBiYmIUFxfnsc/999+vO++8UzNmzFDbtm01fPjwYvNyjRw5UgEBARo5cmSZ+nL+YDL8PZGEj6WmpioyMlIpKSmKiIjwdzkAgFJkZ2dr9+7datGiRZX9x/RM5nQ61bZtW11zzTV68MEH/V3OaXOy3zP6Di58DgBQNvRd/K+m9F9Ks2fPHrVs2VKbNm06LWFhZfSfuHwPAAC47d27V59++qkGDBggu92uefPmaffu3br22mv9XRoAAIBX9F885ebm6siRI5o+fbrOPfdcv4xeKysu3wMAAG5ms1lLlixRz5491a9fP23btk2fffYZ8zgBAIAqi/6Lp/Xr16tBgwbatGmTFixY4O9yToqRUgAAwK1JkyZav369v8sAAAAoM/ovngYOHKjqMlMTI6UAAAAAAADgc4RSAAAAAAAA8DlCKQAAAAAAAPgcoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAoIoaOHCgJk+e7F5v3ry55s6de9JjTCaTVq5cecqvXVnnAQAANQv9F5QHoRQAAJVs6NChuuSSS7xu+/rrr2UymfTTTz+V+7ybNm3STTfddKrleZg5c6a6dOlSrH3//v0aPHhwpb5WUUuWLFGtWrVO62sAAICyof9SPllZWapdu7bq1q0ru93uk9c8ExFKAQBQycaPH6+1a9fq77//LrZt8eLF6tGjhzp16lTu89arV08hISGVUWKpYmJiZLPZfPJaAADA/+i/lM///vc/tW/fXm3atPH76CzDMJSXl+fXGiqKUAoAgEp22WWXqV69elqyZIlHe3p6upYvX67x48fryJEjGjlypBo1aqSQkBB17NhRb7311knPW3T4+++//67+/fsrKChI7dq109q1a4sdc/fdd+vss89WSEiIzjrrLN1///3Kzc2V5BqpNGvWLG3dulUmk0kmk8ldc9Hh79u2bdMFF1yg4OBg1alTRzfddJPS09Pd28eOHau4uDg9+eSTatCggerUqaOJEye6X6sikpKSdPnllyssLEwRERG65pprdODAAff2rVu36vzzz1d4eLgiIiLUvXt3bd68WZK0d+9eDR06VFFRUQoNDVX79u21evXqCtcCAMCZjv5L+fovCxcu1PXXX6/rr79eCxcuLLb9559/1mWXXaaIiAiFh4frvPPO0x9//OHevmjRIrVv3142m00NGjTQpEmTJEl79uyRyWRSYmKie9/jx4/LZDJp3bp1kqR169bJZDLp448/Vvfu3WWz2fTNN9/ojz/+0OWXX67o6GiFhYWpZ8+e+uyzzzzqstvtuvvuu9WkSRPZbDa1atVKCxculGEYatWqlZ588kmP/RMTE2UymbRr165SP5OKCDgtZwUA4HQyDCk30/evGxgimUyl7hYQEKDRo0dryZIluu+++2TKP2b58uVyOBwaOXKk0tPT1b17d919992KiIjQqlWrNGrUKLVs2VK9evUq9TWcTqeuuOIKRUdH6/vvv1dKSorH/A0FwsPDtWTJEjVs2FDbtm3TjTfeqPDwcN11110aPny4tm/frk8++cTdYYmMjCx2joyMDMXGxqpPnz7atGmTDh48qAkTJmjSpEkeHdcvvvhCDRo00BdffKFdu3Zp+PDh6tKli2688cZS34+391cQSH355ZfKy8vTxIkTNXz4cHeH7LrrrlPXrl01f/58WSwWJSYmKjAwUJI0ceJE5eTk6KuvvlJoaKh++eUXhYWFlbsOAAAqhb/6LhL9l9PQf/njjz+0YcMGvffeezIMQ3fccYf27t2rZs2aSZL27dun/v37a+DAgfr8888VERGh9evXu0czzZ8/X1OmTNGjjz6qwYMHKyUlRevXry/18yvqnnvu0ZNPPqmzzjpLUVFR+uuvvzRkyBA9/PDDstlseu211zR06FDt3LlTTZs2lSSNHj1aGzZs0LPPPqvOnTtr9+7dOnz4sEwmk2644QYtXrxYU6dOdb/G4sWL1b9/f7Vq1arc9ZUFoRQAoPrJzZQeaej71733H8kaWqZdb7jhBj3xxBP68ssvNXDgQEmuf9SvvPJKRUZGKjIy0uMf/FtvvVVr1qzRO++8U6ZO3WeffaZff/1Va9asUcOGrs/ikUceKTaPwvTp093LzZs319SpU7Vs2TLdddddCg4OVlhYmAICAhQTE1Piay1dulTZ2dl67bXXFBrqev/z5s3T0KFD9dhjjyk6OlqSFBUVpXnz5slisahNmza69NJLlZCQUKFQKiEhQdu2bdPu3bvVpEkTSdJrr72m9u3ba9OmTerZs6eSkpL03//+V23atJEktW7d2n18UlKSrrzySnXs2FGSdNZZZ5W7BgAAKo2/+i4S/ZfT0H9ZtGiRBg8erKioKElSbGysFi9erJkzZ0qSnn/+eUVGRmrZsmXuL8zOPvts9/EPPfSQ7rzzTt1+++3utp49e5b6+RU1e/ZsXXTRRe712rVrq3Pnzu71Bx98UCtWrNAHH3ygSZMm6bffftM777yjtWvXatCgQZI8+0hjx47VjBkztHHjRvXq1Uu5ublaunRpsdFTlYnL9wAAOA3atGmjvn37atGiRZKkXbt26euvv9b48eMlSQ6HQw8++KA6duyo2rVrKywsTGvWrFFSUlKZzr9jxw41adLE3aGTpD59+hTb7+2331a/fv0UExOjsLAwTZ8+vcyvUfi1Onfu7O7QSVK/fv3kdDq1c+dOd1v79u1lsVjc6w0aNNDBgwfL9VqFX7NJkybuQEqS2rVrp1q1amnHjh2SpClTpmjChAkaNGiQHn30UY8h8bfddpseeugh9evXTw888ECFJmYFAKCmof9Sev/F4XDo1Vdf1fXXX+9uu/7667VkyRI5nU5JrkvezjvvPHcgVdjBgwf1zz//6MILLyzX+/GmR48eHuvp6emaOnWq2rZtq1q1aiksLEw7duxwf3aJiYmyWCwaMGCA1/M1bNhQl156qfvn/+GHH8put+vqq68+5VpLwkgpAED1Exji+tbPH69bDuPHj9ett96q559/XosXL1bLli3dnYAnnnhCzzzzjObOnauOHTsqNDRUkydPVk5OTqWVu2HDBl133XWaNWuWYmNj3d/YzZkzp9Jeo7CiHS+TyeTunJ0OM2fO1LXXXqtVq1bp448/1gMPPKBly5Zp2LBhmjBhgmJjY7Vq1Sp9+umnio+P15w5c3TrrbeetnoAACiRv/ouBa9dDvRfTt5/WbNmjfbt26fhw4d7tDscDiUkJOiiiy5ScHBwicefbJskmc2usUOGYbjbSprjqnDgJklTp07V2rVr9eSTT6pVq1YKDg7WVVdd5f75lPbakjRhwgSNGjVKTz/9tBYvXqzhw4ef1onqGSkFAKh+TCbXMHRfP8owH0Nh11xzjcxms5YuXarXXntNN9xwg3t+hvXr1+vyyy/X9ddfr86dO+uss87Sb7/9VuZzt23bVn/99Zf279/vbvvuu+889vn222/VrFkz3XffferRo4dat26tvXv3euxjtVrlcDhKfa2tW7cqIyPD3bZ+/XqZzWadc845Za65PAre319//eVu++WXX3T8+HG1a9fO3Xb22Wfrjjvu0KeffqorrrhCixcvdm9r0qSJbr75Zr333nu688479fLLL5+WWgEAKJW/+i70Xyq9/7Jw4UKNGDFCiYmJHo8RI0a4Jzzv1KmTvv76a69hUnh4uJo3b66EhASv569Xr54keXxGhSc9P5n169dr7NixGjZsmDp27KiYmBjt2bPHvb1jx45yOp368ssvSzzHkCFDFBoaqvnz5+uTTz7RDTfcUKbXrihCKQAATpOwsDANHz5c06ZN0/79+zV27Fj3ttatW2vt2rX69ttvtWPHDv3f//2fx53lSjNo0CCdffbZGjNmjLZu3aqvv/5a9913n8c+rVu3VlJSkpYtW6Y//vhDzz77rFasWOGxT/PmzbV7924lJibq8OHDstvtxV7ruuuuU1BQkMaMGaPt27friy++0K233qpRo0a552OoKIfDUaxTt2PHDg0aNEgdO3bUddddpy1btmjjxo0aPXq0BgwYoB49eigrK0uTJk3SunXrtHfvXq1fv16bNm1S27ZtJUmTJ0/WmjVrtHv3bm3ZskVffPGFexsAACgZ/ZeSHTp0SB9++KHGjBmjDh06eDxGjx6tlStX6ujRo5o0aZJSU1M1YsQIbd68Wb///rtef/1192WDM2fO1Jw5c/Tss8/q999/15YtW/Tcc89Jco1mOvfcc/Xoo49qx44d+vLLLz3m2DqZ1q1b67333lNiYqK2bt2qa6+91mPUV/PmzTVmzBjdcMMNWrlypXbv3q1169bpnXfece9jsVg0duxYTZs2Ta1bt/Z6eWVlIpQCAOA0Gj9+vI4dO6bY2FiP+ROmT5+ubt26KTY2VgMHDlRMTIzi4uLKfF6z2awVK1YoKytLvXr10oQJE/Twww977PPvf/9bd9xxhyZNmqQuXbro22+/1f333++xz5VXXqlLLrlE559/vurVq+f1ts4hISFas2aNjh49qp49e+qqq67ShRdeqHnz5pXvw/AiPT1dXbt29XgMHTpUJpNJ77//vqKiotS/f38NGjRIZ511lt5++21Jrg7TkSNHNHr0aJ199tm65pprNHjwYM2aNUuSK+yaOHGi2rZtq0suuURnn322XnjhhVOuFwCAmoD+i3cFk6Z7mw/qwgsvVHBwsN544w3VqVNHn3/+udLT0zVgwAB1795dL7/8svtSwTFjxmju3Ll64YUX1L59e1122WX6/fff3edatGiR8vLy1L17d02ePFkPPfRQmep76qmnFBUVpb59+2ro0KGKjY1Vt27dPPaZP3++rrrqKv3nP/9RmzZtdOONN3qMJpNcP/+cnByNGzeuvB9RuZmMwhcq1gCpqamKjIxUSkqKIiIi/F0OAKAU2dnZ2r17t1q0aKGgoCB/l4Mz1Ml+z+g7uPA5AEDZ0HdBdff111/rwgsv1F9//XXSUWWV0X9ionMAAAAAAIAazm6369ChQ5o5c6auvvrqU56moSy4fA8AAAAAAKCGe+utt9SsWTMdP35cjz/+uE9ek1AKAAAAAACghhs7dqwcDod++OEHNWrUyCevSSgFAAAAAAAAnyOUAgAAAAAAgM8RSgEAqgWn0+nvEnAG4/cLAFDZ+LcFZ7rK+B3n7nsAgCrNarXKbDbrn3/+Ub169WS1WmUymfxdFs4QhmEoJydHhw4dktlsltVq9XdJAIBqjr4LznSV2X8ilAIAVGlms1ktWrTQ/v379c8///i7HJyhQkJC1LRpU5nNDCIHAJwa+i6oKSqj/0QoBQCo8qxWq5o2baq8vDw5HA5/l4MzjMViUUBAAN9iAwAqDX0XnOkqq/9EKAUAqBZMJpMCAwMVGBjo71IAAABKRd8FKB1j1AEAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM/5NZSKj49Xz549FR4ervr16ysuLk47d+486TFLliyRyWTyeAQFBfmoYgAAAAAAAFQGv4ZSX375pSZOnKjvvvtOa9euVW5uri6++GJlZGSc9LiIiAjt37/f/di7d6+PKgYAAAAAAEBlCPDni3/yySce60uWLFH9+vX1ww8/qH///iUeZzKZFBMTc7rLAwAAAAAAwGlSpeaUSklJkSTVrl37pPulp6erWbNmatKkiS6//HL9/PPPvigPAAAAAAAAlaTKhFJOp1OTJ09Wv3791KFDhxL3O+ecc7Ro0SK9//77euONN+R0OtW3b1/9/fffXve32+1KTU31eAAAAAAAAMC//Hr5XmETJ07U9u3b9c0335x0vz59+qhPnz7u9b59+6pt27Z68cUX9eCDDxbbPz4+XrNmzar0egEAAAAAAFBxVWKk1KRJk/TRRx/piy++UOPGjct1bGBgoLp27apdu3Z53T5t2jSlpKS4H3/99VdllAwAAAAAAIBT4NeRUoZh6NZbb9WKFSu0bt06tWjRotzncDgc2rZtm4YMGeJ1u81mk81mO9VSAQAAAAAAUIn8GkpNnDhRS5cu1fvvv6/w8HAlJydLkiIjIxUcHCxJGj16tBo1aqT4+HhJ0uzZs3XuueeqVatWOn78uJ544gnt3btXEyZM8Nv7AAAAAAAAQPn4NZSaP3++JGngwIEe7YsXL9bYsWMlSUlJSTKbT1xleOzYMd14441KTk5WVFSUunfvrm+//Vbt2rXzVdkAAAAAAAA4RSbDMAx/F+FLqampioyMVEpKiiIiIvxdDgAAqOLoO7jwOQAAgLIqa7+hSkx0DgAAAAAAgJqFUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAqIaef/55NW/eXEFBQerdu7c2btx40v3nzp2rc845R8HBwWrSpInuuOMOZWdn+6haAACA4vx69z0AAACU39tvv60pU6ZowYIF6t27t+bOnavY2Fjt3LlT9evXL7b/0qVLdc8992jRokXq27evfvvtN40dO1Ymk0lPPfWUH94BAACoDA6noXR7nuuRnad0e67Ssguvey6nFW7PztNbN52r2qFWv9VPKAUAAFDNPPXUU7rxxhs1btw4SdKCBQu0atUqLVq0SPfcc0+x/b/99lv169dP1157rSSpefPmGjlypL7//nuf1g0AACTDMGTPcyotO08Z+aGRO0iy5yo9+0R4lFE0SMpfLmjLynWcUi1p2bmEUgAAACibnJwc/fDDD5o2bZq7zWw2a9CgQdqwYYPXY/r27as33nhDGzduVK9evfTnn39q9erVGjVqVImvY7fbZbfb3eupqamV9yYAAKiGHE5DGTmFRh0VCpUKB0Xp9txi29OKhEp5TqNSa7MGmBVuC1CoLUBhtgCFBQUoPP+58HrB9vCgAIXZAlUv3FapdZQXoRQAAEA1cvjwYTkcDkVHR3u0R0dH69dff/V6zLXXXqvDhw/rX//6lwzDUF5enm6++Wbde++9Jb5OfHy8Zs2aVam1AwBwMg6noVyHUzkOp3LzCp4N13OhR06e4bnuMJSbV2Q9/xwe6+U93l2HoaycPGXknNqoJG/CCoVIBWFRqNVzvaTt4bZAhQUFKNRmkS3AUum1+QKhFAAAwBlu3bp1euSRR/TCCy+od+/e2rVrl26//XY9+OCDuv/++70eM23aNE2ZMsW9npqaqiZNmviqZABAFZLncF1qlpadp7T8OYtcj1yP59T80UD2XEd+qFMkUMorFDrlb3eHTw6nKnnw0GkTaDEVCooCi41IcgdNXkYshQedGK0Uag2Q2Wzy99vxK0IpAACAaqRu3bqyWCw6cOCAR/uBAwcUExPj9Zj7779fo0aN0oQJEyRJHTt2VEZGhm666Sbdd999MpuL35DZZrPJZvPvkH4AwKmz5zlcl5YVCpJSPQIl13LBJWapRYKmtEqYt6iiAi0mBVrM7ofVYlJgQJH1gu0BRdYtZlkDvByfv2/hdWvAyY4xK8BiUojV4g6ZquuopKqIUAoAAKAasVqt6t69uxISEhQXFydJcjqdSkhI0KRJk7wek5mZWSx4slhcHWrDqCZfSwNADVMwGXZqdikjkwq3FxnFlJqdp5w8Z6XVFBRoVnhQoMKDAhQeFKiIINfIn3Cbqy0svz040KJAi8kj7Am0mGQtFAi5191thdbzt5tMNXsUUU1AKAUAAFDNTJkyRWPGjFGPHj3Uq1cvzZ07VxkZGe678Y0ePVqNGjVSfHy8JGno0KF66qmn1LVrV/fle/fff7+GDh3qDqcAAJXP6TSUmp2r45m5Op6Vq2OZOUrJzNXxzBwdz3K1exuZVDByKddReV8chFothQKlAI9wKTz/EjNv7RFBJwKnQEvxkbXAqSCUAgAAqGaGDx+uQ4cOacaMGUpOTlaXLl30ySefuCc/T0pK8hgZNX36dJlMJk2fPl379u1TvXr1NHToUD388MP+egsAUK04nYbSsvN0zB0m5SglK1fHMk6ES4WDpoLllKxcneqAVJPJNRl2hJdAyTVHUUF45CVoKjQZtqWGz12Eqslk1LAx26mpqYqMjFRKSooiIiL8XQ4AAKji6Du48DkAOBMUhEvHs3J0LPNEuHQ80zWK6XimK0gqunyq4VKo1aJaIVbVCgl0PYJdy5HBgYoILjoyybVc+E5rNX0ybFQ/Ze03MFIKAAAAAFCtFA6XCgIlb+HS8UxX+JRSaHTTqdzhzVu4FBkSqCiP5fztwYGqFWJVZHCgrAFc9gZ4QygFAAAAADgt8hxOZeU6lJXrUHaOU5m5ecrKyV/PdSgzx6GsHNdyVsF6rkPZOYWW87dl2B2VHi5FBgcqKtR7uFQrOFBRoVbVCg7MX7cSLgGVjFAKAAAAAGogh9NwBUY5hQKi/PWs3Dxl5ZwIlLJyTqy79s1TVq6z0L4OZeU6T2zLcSg716kcR+Xd+c2bEKtFUfnhUq38UUruQKnQcq0Qq6JCXOFSZHCgbAHc5AGoCgilAAAAAKCaMAxDmTkO1yTa+ZelpWTl5D/nui9hS8vOKxQweXnOdSgn7/QGRoWZTFJwoEUhVouCAi2ey1bPdvc2q6XYMYRLwJmFUAoAAAAAfCw71+ERIp1YzlFqwXKhoCmlUAiVdyrXrZUgOD8c8vpcJCQquo9HoFTk2IJttgCzTCYm6wbgiVAKAAAAACogJ8/pGRoVjFjKzFVKlmsS7pSsXKUWDZ6yck95lFKgxaTI4ECPR8EcSRHBgYoIClCINUDBVrOCAwM8AqZgq2doRGAEwF8IpQAAAADUWA6n4X1kUmbxS+JSioxcysxxnNJrm006ESrlB0quR4Brsm33tsLBk+s5ONBCkASg2iOUAgAAAFDtGYahdHuejme6AqRjmTk6lh8sHcvIPbGcmaNjma7L5I5n5io1O1fGKV4NFxEU4BkcBVsVUSREcrUHutsjQwIVZg2Q2UywBKDmIpQCAAAAUKVk5zpc4VJWjo5l5AdI+YHS8cxcHctwrR93B0yuS+dyHRVPl0KtlkIjlgLc4VJB2BSRHyoVHbEUHhQoC8ESAFQIoRQAAACA0yLP4cwfneQKjbyNWErJLD56KSu34pfF2QLMigqxqlaIKzhyLVvzl13zLtUKDlRUaP5d3IJd2wIt5kp85wCAsiCUAgAAAFAiwzBkz3MqLTtPGfY8pWbnugOkEyOWToxiOl4oYErNzqvw61rMJtXKH5FUK8TqDpTcwVJB4JQ/wXdUqGtkU7DVUonvHgBwOhFKAQAAAGcYwzCUletQuj1PGXaH0rPzlG7Py1/3XC4ImzJyTiy7j8tfdjhPbdKl8KAAReUHSpH5z1H5E3tHhbhGLblHMIVYVSs0UOG2ACbyBoAzHKEUAAAAUAUYhqHMHIdneFQsTHIo3Z6rDLujxDCpYN9TzJG8CrMFKDwooNCIpUKjl4ILjV4q1B4ZHKgALo0DAHhBKAUAAABUAnueQ0czcnQkPcf1nGFXWrb3wCi9IGDKdgVMGfY8pefknfJd4IoymaQwa4BCbQEKC3I9h9sCFGqzFFp2bQuzBSjUemI5rGBb/vaQQAt3igMAVCpCKQAAAMALbyGTezk9R0cycnQ0w+56Ts9Rmr3i8ycVZjbJMxTyFhK5ly2usKlQmFQ4bAqxWrgEDgBQZRFKAQAAoEbwRcgUYDYpKtSqOqFW1QlzzZlU4uijggApfwRTqM2icFugggLNBEkAgBqBUAoAAADVUk6eU0czcnQ43a6jGTkey6crZKodanMth1pVO8yqOqG2/Har6obaFBHM5NwAAJQVoRQAAACqhJOFTK5lV8hUEDoRMgEAUL0RSgEAAMCv3k/cp+krthMyAQBQwxBKAQAAwK9sARZ3IEXIBABAzUEoBQAAAL/q16qOEu4cQMgEAEANQygFAAAAvwoPClR4UKC/ywAAAD5m9ncBAAAAAAAAqHkIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUAAAAAAADgc4RSAAAAAAAA8DlCKQAAAAAAAPgcoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUAAAAAAAAfM6voVR8fLx69uyp8PBw1a9fX3Fxcdq5c2epxy1fvlxt2rRRUFCQOnbsqNWrV/ugWgAAAAAAAFQWv4ZSX375pSZOnKjvvvtOa9euVW5uri6++GJlZGSUeMy3336rkSNHavz48frxxx8VFxenuLg4bd++3YeVAwAAAAAA4FSYDMMw/F1EgUOHDql+/fr68ssv1b9/f6/7DB8+XBkZGfroo4/cbeeee666dOmiBQsWlPoaqampioyMVEpKiiIiIiqtdgAAcGai7+DC5wAAAMqqrP2GAB/WVKqUlBRJUu3atUvcZ8OGDZoyZYpHW2xsrFauXOl1f7vdLrvd7l5PTU099UIBAACAqszplPKypdwsKTezyHNG/rO3bVlSTkbxtsL7GYYUYJUCgiRL/nOAVbLYpIBCD0tJywXHFN5WcD5v+xXaZmZKXKDKMgwpz+76e8JsOfF3hMnk78pQhVWZUMrpdGry5Mnq16+fOnToUOJ+ycnJio6O9miLjo5WcnKy1/3j4+M1a9asSq0VAAAAqDCno1DQ4yUUKljOOVl4VMqxuZn+fpenhzmgeBjmXrdVPCgLDJZsEVJQZP5z/nJAEP+hRvVnGJIj1/PvhxJD6xL+PnG3Fd1W9O8dLxdiuUNob88n21bW55NsIxSr8qpMKDVx4kRt375d33zzTaWed9q0aR4jq1JTU9WkSZNKfQ0AAACcQZzOE6FPTkb+c6ZrhFFOZqFtRdqK7pubVWj/Qv9xc9hLr6EyWfJDl8AQz2drSKE2L9sDQ7y3mUyu0RAOu+s5zy45clz/yXWv26W8/Db3tpz89uwi2+xezldoufB/cp15Uk667z47c6AroCocVHkLrwqW3c+RrvagCNd/jlFcwZ+znIz8P0f5f5Zy0k+0FzxyC9qzXb9/JotkMrtGzpksrlE5pqLL5vxlS6Fls5d9i5yr8HFmy4nXK3au/G0e+xac18u5SqrBZHb9vpc5GCpHQFS4zXD472edl+16KMU/r19ZoZgl0BWMmwPzly2FlgNcD499AkpY9nasxT+fTRVQJUKpSZMm6aOPPtJXX32lxo0bn3TfmJgYHThwwKPtwIEDiomJ8bq/zWaTzcY/BAAAAGcM97f+JwmEPJ6zyrBv5omRSXlZvnsvxUKfMoRCBftZQ8t2bHX+z07Bz9oj5PIWhhXeVoEwLCdTsqdK2amSPcX1LENy5kqZR1yPirLYCgVWkSWHVx7BVmSh7RGu/7j6iyOv7KFRTjlCpjN1NF9VZzKXEkZ7aQsIPsn+3o4LlgxnoaDa2/PJtpX1+STbCvN3KFYmpjIGWqWFWwGlhGT564WXu41y/Z3jJ34NpQzD0K233qoVK1Zo3bp1atGiRanH9OnTRwkJCZo8ebK7be3aterTp89prBQAAACnTfI26eeVRUYglRIe+epb/4JwxxoiBYaeGF1kDS2yrVBb0X1L+k9cQBBzJJXGZMq/RM8q+fJ7ZqfTFaa4g6r85+yUE6GVR5uX/XLSXOdy2KWMQ65HRQUEly288rj0MLicI5FKCJlO+8g+U6E/O6EnHoXX3X++gl1BpeF0/R3gdOQvO/OXHYWWCz2793W4ji+2r8P1My+2rzO/vei++ecptm9Jr+uU18vaiiotIAoIKnuQVGxbkOvZl5ez+WuUoGEUGb15skDLXsYQLMt1TqfDFZQ7c4ss57kCXGdufpuj0HJe/vb8Za//fuXX7Mjx+celdv+uuaHUxIkTtXTpUr3//vsKDw93zwsVGRmp4OBgSdLo0aPVqFEjxcfHS5Juv/12DRgwQHPmzNGll16qZcuWafPmzXrppZf89j4AAABwCg7+Kn39ZMWONQcUCYtKCI8KjyryGh4VCZGsIa7/1BMa1Uxmc364EyFV9P9qTodkTysSWKV4LhdrK7JfbobrXHlZUnqWlO59Hl2fMFkka1h+UFTw5yTMtWwNzf8zlL/NGlZCyORl/8DgmjHnT0lhmOE8cRlZTfgcfMFkOjFfXFXkdJ4Iqpy5+WFWXgkh1knCr2LLXo51nOx18oMza5hfPw6/hlLz58+XJA0cONCjffHixRo7dqwkKSkpSeZCnYG+fftq6dKlmj59uu699161bt1aK1euPOnk6AAAAKjC6p0t9bqp/OGRNdS/lzUBJ2O2SMG1XI+KcuS5QqqTjso67n2kVp79xGWe3kYfnSwo8hYsMWH0qTGZXJdMVY0ZdOBPZrNktkqy+ruSKsFkGEYZxhGeOVJTUxUZGamUlBRFRET4uxwAAFDF0Xdw4XMAAABlVdZ+A+ORAQAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUAAAAAAAAfI5QCgAAAAAAAD5HKAUAAAAAAACfI5QCAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUAAACqoeeff17NmzdXUFCQevfurY0bN550/+PHj2vixIlq0KCBbDabzj77bK1evdpH1QIAABQX4O8CAAAAUD5vv/22pkyZogULFqh3796aO3euYmNjtXPnTtWvX7/Y/jk5ObroootUv359vfvuu2rUqJH27t2rWrVq+b54AACAfIRSAAAA1cxTTz2lG2+8UePGjZMkLViwQKtWrdKiRYt0zz33FNt/0aJFOnr0qL799lsFBgZKkpo3b+7LkgEAAIrh8j0AAIBqJCcnRz/88IMGDRrkbjObzRo0aJA2bNjg9ZgPPvhAffr00cSJExUdHa0OHTrokUcekcPhKPF17Ha7UlNTPR4AAACViVAKAACgGjl8+LAcDoeio6M92qOjo5WcnOz1mD///FPvvvuuHA6HVq9erfvvv19z5szRQw89VOLrxMfHKzIy0v1o0qRJpb4PAAAAQikAAIAznNPpVP369fXSSy+pe/fuGj58uO677z4tWLCgxGOmTZumlJQU9+Ovv/7yYcUAAKAmYE4pAACAaqRu3bqyWCw6cOCAR/uBAwcUExPj9ZgGDRooMDBQFovF3da2bVslJycrJydHVqu12DE2m002m61yiwcAACiEkVIAAADViNVqVffu3ZWQkOBuczqdSkhIUJ8+fbwe069fP+3atUtOp9Pd9ttvv6lBgwZeAykAAABfIJQCAACoZqZMmaKXX35Zr776qnbs2KFbbrlFGRkZ7rvxjR49WtOmTXPvf8stt+jo0aO6/fbb9dtvv2nVqlV65JFHNHHiRH+9BQAAAC7fAwAAqG6GDx+uQ4cOacaMGUpOTlaXLl30ySefuCc/T0pKktl84rvHJk2aaM2aNbrjjjvUqVMnNWrUSLfffrvuvvtuf70FAAAAmQzDMPxdhC+lpqYqMjJSKSkpioiI8Hc5AACgiqPv4MLnAAAAyqqs/QYu3wMAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAfaN68uWbPnq2kpCR/lwIAAFAlEEoBAAD4wOTJk/Xee+/prLPO0kUXXaRly5bJbrf7uywAAAC/IZQCAADwgcmTJysxMVEbN25U27Ztdeutt6pBgwaaNGmStmzZ4u/yAAAAfI5QCgAAwIe6deumZ599Vv/8848eeOABvfLKK+rZs6e6dOmiRYsWyTAMf5cIAADgEwH+LgAAAKAmyc3N1YoVK7R48WKtXbtW5557rsaPH6+///5b9957rz777DMtXbrU32UCAACcdoRSAAAAPrBlyxYtXrxYb731lsxms0aPHq2nn35abdq0ce8zbNgw9ezZ049VAgAA+A6hFAAAgA/07NlTF110kebPn6+4uDgFBgYW26dFixYaMWKEH6oDAADwPUIpAAAAH/jzzz/VrFmzk+4TGhqqxYsX+6giAAAA/2KicwAAAB84ePCgvv/++2Lt33//vTZv3uyHigAAAPyLUAoAAMAHJk6cqL/++qtY+759+zRx4kQ/VAQAAOBfhFIAAAA+8Msvv6hbt27F2rt27apffvnFDxUBAAD4F6EUAACAD9hsNh04cKBY+/79+xUQwDSfAACg5iGUAgAA8IGLL75Y06ZNU0pKirvt+PHjuvfee3XRRRf5sTIAAAD/4Gs5AAAAH3jyySfVv39/NWvWTF27dpUkJSYmKjo6Wq+//rqfqwMAAPA9QikAAAAfaNSokX766Se9+eab2rp1q4KDgzVu3DiNHDlSgYGB/i4PAADA5wilAAAAfCQ0NFQ33XSTv8sAAACoEgilAAAAfOiXX35RUlKScnJyPNr//e9/+6kiAAAA/yCUAgAA8IE///xTw4YN07Zt22QymWQYhiTJZDJJkhwOhz/LAwAA8LkK3X3vr7/+0t9//+1e37hxoyZPnqyXXnqp0goDAAA4k9x+++1q0aKFDh48qJCQEP3888/66quv1KNHD61bt87f5QEAAPhchUKpa6+9Vl988YUkKTk5WRdddJE2btyo++67T7Nnz67UAgEAAM4EGzZs0OzZs1W3bl2ZzWaZzWb961//Unx8vG677TZ/lwcAAOBzFQqltm/frl69ekmS3nnnHXXo0EHffvut3nzzTS1ZsqQy6wMAADgjOBwOhYeHS5Lq1q2rf/75R5LUrFkz7dy505+lAQAA+EWF5pTKzc2VzWaTJH322WfuiTnbtGmj/fv3V151AAAAZ4gOHTpo69atatGihXr37q3HH39cVqtVL730ks466yx/lwcAAOBzFRop1b59ey1YsEBff/211q5dq0suuUSS9M8//6hOnTqVWiAAAMCZYPr06XI6nZKk2bNna/fu3TrvvPO0evVqPfvss36uDgAAwPcqNFLqscce07Bhw/TEE09ozJgx6ty5syTpgw8+cF/WBwAAgBNiY2Pdy61atdKvv/6qo0ePKioqyn0HPgAAgJqkQqHUwIEDdfjwYaWmpioqKsrdftNNNykkJKTSigMAADgT5ObmKjg4WImJierQoYO7vXbt2n6sCgAAwL8qdPleVlaW7Ha7O5Dau3ev5s6dq507d6p+/fplPs9XX32loUOHqmHDhjKZTFq5cuVJ91+3bp1MJlOxR3JyckXeBgAAgE8EBgaqadOmcjgc/i4FAACgyqhQKHX55ZfrtddekyQdP35cvXv31pw5cxQXF6f58+eX+TwZGRnq3Lmznn/++XK9/s6dO7V//373ozxBGAAAgD/cd999uvfee3X06FF/lwIAAFAlVOjyvS1btujpp5+WJL377ruKjo7Wjz/+qP/973+aMWOGbrnlljKdZ/DgwRo8eHC5X79+/fqqVatWuY8DAADwl3nz5mnXrl1q2LChmjVrptDQUI/tW7Zs8VNlAAAA/lGhUCozM1Ph4eGSpE8//VRXXHGFzGazzj33XO3du7dSC/SmS5custvt6tChg2bOnKl+/fqd9tcEAAA4FXFxcf4uAQAAoEqpUCjVqlUrrVy5UsOGDdOaNWt0xx13SJIOHjyoiIiISi2wsAYNGmjBggXq0aOH7Ha7XnnlFQ0cOFDff/+9unXr5vUYu90uu93uXk9NTT1t9QEAAJTkgQce8HcJAAAAVUqFQqkZM2bo2muv1R133KELLrhAffr0keQaNdW1a9dKLbCwc845R+ecc457vW/fvvrjjz/09NNP6/XXX/d6THx8vGbNmnXaagIAAAAAAED5VWii86uuukpJSUnavHmz1qxZ426/8MIL3XNN+UqvXr20a9euErdPmzZNKSkp7sdff/3lw+oAAABczGazLBZLiQ8AAICapkIjpSQpJiZGMTEx+vvvvyVJjRs3Vq9evSqtsLJKTExUgwYNStxus9lks9l8WBEAAEBxK1as8FjPzc3Vjz/+qFdffZVR3QAAoEaqUCjldDr10EMPac6cOUpPT5ckhYeH684779R9990ns7lsA7DS09M9Rjnt3r1biYmJql27tpo2bapp06Zp3759eu211yRJc+fOVYsWLdS+fXtlZ2frlVde0eeff65PP/20Im8DAADAZy6//PJibVdddZXat2+vt99+W+PHj/dDVQAAAP5ToVDqvvvu08KFC/Xoo4+673z3zTffaObMmcrOztbDDz9cpvNs3rxZ559/vnt9ypQpkqQxY8ZoyZIl2r9/v5KSktzbc3JydOedd2rfvn0KCQlRp06d9Nlnn3mcAwAAoDo599xzddNNN/m7DAAAAJ8zGYZhlPeghg0basGCBfr3v//t0f7+++/rP//5j/bt21dpBVa21NRURUZGKiUl5bTeKRAAAJwZTmffISsrS9OmTdPHH3+snTt3Vuq5Kxt9KAAAUFZl7TdUaKTU0aNH1aZNm2Ltbdq00dGjRytySgAAgDNaVFSUTCaTe90wDKWlpSkkJERvvPGGHysDAADwjwqFUp07d9a8efP07LPPerTPmzdPnTp1qpTCAAAAziRPP/20RyhlNptVr1499e7dW1FRUX6sDAAAwD8qFEo9/vjjuvTSS/XZZ5+pT58+kqQNGzbor7/+0urVqyu1QAAAgDPB2LFj/V0CAABAlVK22+QVMWDAAP32228aNmyYjh8/ruPHj+uKK67Qzz//rNdff72yawQAAKj2Fi9erOXLlxdrX758uV599VU/VAQAAOBfFZrovCRbt25Vt27d5HA4KuuUlY5JOgEAQHlUVt/h7LPP1osvvljsrsFffvmlbrrpJiY6BwAAZ4yy9hsqNFIKAAAA5ZOUlKQWLVoUa2/WrJmSkpL8UBEAAIB/EUoBAAD4QP369fXTTz8Va9+6davq1Knjh4oAAAD8i1AKAADAB0aOHKnbbrtNX3zxhRwOhxwOhz7//HPdfvvtGjFihL/LAwAA8Lly3X3viiuuOOn248ePn0otAAAAZ6wHH3xQe/bs0YUXXqiAAFcXzOl0avTo0XrkkUf8XB0AAIDvlSuUioyMLHX76NGjT6kgAACAM5HVatXbb7+thx56SImJiQoODlbHjh3VrFkzf5cGAADgF+UKpRYvXny66gAAAKgRWrdurdatW/u7DAAAAL9jTikAAAAfuPLKK/XYY48Va3/88cd19dVX+6EiAAAA/yKUAgAA8IGvvvpKQ4YMKdY+ePBgffXVV36oCAAAwL8IpQAAAHwgPT1dVqu1WHtgYKBSU1P9UBEAAIB/EUoBAAD4QMeOHfX2228Xa1+2bJnatWvnh4oAAAD8q1wTnQMAAKBi7r//fl1xxRX6448/dMEFF0iSEhIStHTpUr377rt+rg4AAMD3CKUAAAB8YOjQoVq5cqUeeeQRvfvuuwoODlbnzp31+eefq3bt2v4uDwAAwOcIpQAAAHzk0ksv1aWXXipJSk1N1VtvvaWpU6fqhx9+kMPh8HN1AAAAvsWcUgAAAD701VdfacyYMWrYsKHmzJmjCy64QN99952/ywIAAPA5RkoBAACcZsnJyVqyZIkWLlyo1NRUXXPNNbLb7Vq5ciWTnAMAgBqLkVIAAACn0dChQ3XOOefop59+0ty5c/XPP//oueee83dZAAAAfsdIKQAAgNPo448/1m233aZbbrlFrVu39nc5AAAAVQYjpQAAAE6jb775Rmlpaerevbt69+6tefPm6fDhw/4uCwAAwO8IpQAAAE6jc889Vy+//LL279+v//u//9OyZcvUsGFDOZ1OrV27Vmlpaf4uEQAAwC8IpQAAAHwgNDRUN9xwg7755htt27ZNd955px599FHVr19f//73v/1dHgAAgM8RSgEAAPjYOeeco8cff1x///233nrrLX+XAwAA4BeEUgAAAH5isVgUFxenDz74wN+lAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAABQDT3//PNq3ry5goKC1Lt3b23cuLFMxy1btkwmk0lxcXGnt0AAAIBSEEoBAABUM2+//bamTJmiBx54QFu2bFHnzp0VGxurgwcPnvS4PXv2aOrUqTrvvPN8VCkAAEDJCKUAAACqmaeeeko33nijxo0bp3bt2mnBggUKCQnRokWLSjzG4XDouuuu06xZs3TWWWf5sFoAAADvCKUAAACqkZycHP3www8aNGiQu81sNmvQoEHasGFDicfNnj1b9evX1/jx431RJgAAQKkC/F0AAAAAyu7w4cNyOByKjo72aI+Ojtavv/7q9ZhvvvlGCxcuVGJiYplfx263y263u9dTU1MrVC8AAEBJGCkFAABwBktLS9OoUaP08ssvq27dumU+Lj4+XpGRke5HkyZNTmOVAACgJmKkFAAAQDVSt25dWSwWHThwwKP9wIEDiomJKbb/H3/8oT179mjo0KHuNqfTKUkKCAjQzp071bJly2LHTZs2TVOmTHGvp6amEkwBAIBKRSgFAABQjVitVnXv3l0JCQmKi4uT5AqZEhISNGnSpGL7t2nTRtu2bfNomz59utLS0vTMM8+UGDTZbDbZbLZKrx8AAKAAoRQAAEA1M2XKFI0ZM0Y9evRQr169NHfuXGVkZGjcuHGSpNGjR6tRo0aKj49XUFCQOnTo4HF8rVq1JKlYOwAAgC8RSgEAAFQzw4cP16FDhzRjxgwlJyerS5cu+uSTT9yTnyclJclsZupQAABQtZkMwzD8XYQvpaamKjIyUikpKYqIiPB3OQAAoIqj7+DC5wAAAMqqrP0GvkIDAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+FyAvwsAAACQJOXZJXuaZE+V7Omu5Zz854KHe73IPq0vkvr/19/vAAAAAOVAKAUAACouLyc/KCoUEtnTpJyCIKlwuFR0nyJtztyK1xHVvNLeEgAAAHyDUAoAgJrGkVtk1FF6kSCpoC219H0c9sqvLzBUsoVJtnDJmv9c+FG0zRpGKAUAAFANEUoBAFDVOfLyw6B0KSfjRFCUk7/uDpgKthfsW7A93bMtL7vyawwIPhEk2cIla0FoVDhciiihrUgAZbZUfn0AAACocgilAACobO6RSBmFwqK0QgFRuvftJYVOpyNEkiSLzTMkskUUGoUU5j1c8ho4hUsWuhQAAAAoH3qQAICawzBcgZEjx/XIs7suP8vLcT07ck4s5+W4wqDyhEoF20/HJW2SZLFK1tD8UCjMFSBZ8y91c7eFngiWStpeED4FWE9PnQAAAEAZEEoBqDpys6SMQ/mPwyeeLYFSUC0puJYUHOW5HBjs35pRMqczP9yxFwmBvDwXa7O7wqOibXk5JwmUck/SVuj8Mnz3GVhsFQuNim0PJ0QCAADAGYdQCsDp48iTso56CZq8rR92jTgpL4vNFVAF1XKFVF6XaxUPs4Jq8R/8ogrmLcpOzZ/EOv85O/XEskdbwXrqiVFDeflBkMMuOfP8/Y5KZ7JIATZX8Gmx5S9bPZ+tYRULlQiRAAAAgJMilAJQdobhCiBKC5cKljOPqtyjUixWKbS+FFpHCq0nhdR1hRvZx6Ws41LWsRPLhsMVfqQfcD3KKzDEM6wqa5gVFFm15s9xOgvdIa2cQVLhttzM01unxZof/OQ/WwLzwx9vbdYi26xe2ko4h3v/wm22Quco1MaE2gAAAIDfVKH/VQHwi9xsKfNw2UYyZRzKv/ypPExSSH7AFFo3/7mel/X8ZVu4ZDKVflrDcAUxWcdcAVX28ZMsH/cMs7JTJBmuECY3U0rdV873JNecPEG1pODIUkZpFQm5bJGS2XziPeRmeYZH5R6llOZ6VOYlaQFBJ+6SFlRwt7QIL22F2oMiXCHfyQKlsvxcAQAAANQYhFLAmcbpcAUwZRnJlHHYFWyUlzXce6DkLXgKqX16RqOYTCeCkVpNy3es0ynZU8oQZhVeTnGt56S5zlEw2iil3IW7RlqZTK4wqTIvcTMHnAiIbOGuAKzgM/IIl8KL7FcQNkVyyRkAAAAAn/FrKPXVV1/piSee0A8//KD9+/drxYoViouLO+kx69at05QpU/Tzzz+rSZMmmj59usaOHeuTegGfKBg9k53i5XH8xLI9tfj2rOOuOZwMZ/le0xxYerjkXq9b/ScXN5vzRzBFlf9YR17+Z32shFFYx0sOtnIzJRmu5cJM5rKPRvJoyw+SCtYDbIxGAgAAAFBt+DWUysjIUOfOnXXDDTfoiiuuKHX/3bt369JLL9XNN9+sN998UwkJCZowYYIaNGig2NhYH1QMlIGRf1mYR2CUWjxUOtnDmXvqdQTXLttIptC6J0buoHSWgPz5ruqU/9g8+4mASjoRLFlD+fwBAAAA1Dh+DaUGDx6swYMHl3n/BQsWqEWLFpozZ44kqW3btvrmm2/09NNPE0o5HVJetus/ve5botuLrGe7bpOel51/e/TC6/aTbMtx3U3LHJB/h6pA18gaS4BrnpiTLhfePzD/HFYvy1729fo6gaf/P+9eQ6USRiuVGCpVwiVZJosrLCrxUctLW4RrYvCQOlVrIm64BNik8GjXAwAAAABquGr1v9YNGzZo0KBBHm2xsbGaPHmyfwry5niSlJNZPNwpUyhUNEQqR6hkOPz9zn3HHFBKiHWy8KvQssmcP2m0l1CpMj7PCoVKhR6MngEAAAAAnMGqVSiVnJys6GjPEQbR0dFKTU1VVlaWgoOLz3Njt9tlt9vd66mpFZjUuTxe/bd0bPfpfY3SmMyuu2e5735V6GGx5W+zup4t1hLWbZ7HmwNco3+ceSdGTjlzXc9el/P3O9VlbyOOCurIyzq9n6M5oJRQqZRgKTCEUAkAAAAAgBJUq1CqIuLj4zVr1izfvWBIbddIm7IEPSddzz++zKFSoe1n0mVbhlGGAKzIcln3deblTx5NqAQAAAAAgK9Vq/QiJiZGBw4c8Gg7cOCAIiIivI6SkqRp06ZpypQp7vXU1FQ1adLk9BV54+en79w1kcmUf3t6blEPAAAAAMCZpFqFUn369NHq1as92tauXas+ffqUeIzNZpPNZjvdpQEAAAAAAKAczP588fT0dCUmJioxMVGStHv3biUmJiopKUmSa5TT6NGj3fvffPPN+vPPP3XXXXfp119/1QsvvKB33nlHd9xxhz/KBwAAAAAAQAX5NZTavHmzunbtqq5du0qSpkyZoq5du2rGjBmSpP3797sDKklq0aKFVq1apbVr16pz586aM2eOXnnlFcXGxvqlfgAAAAAAAFSMyTAMw99F+FJqaqoiIyOVkpKiiIgIf5cDAACqOPoOLnwOAACgrMrab/DrSCkAAAAAAADUTIRSAAAAAAAA8DlCKQAAAAAAAPgcoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUAAAAAAAAfI5QCgAAAAAAAD5HKAUAAAAAAACfI5QCAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUAAAAAAADgc4RSAAAAAAAA8LkAfxdwpnnl6z+VYXeodmigaofaFBUaqDr5z1EhVgVayAEBAAAAAAAIpSrZ0u+T9OfhjBK3RwQFqE6YTVEhrtCqdmigokKtqhNqVVSIVXXC8p/zg6wwW4BMJpMP3wEAAAAAAMDpRyhVya7s3lh/H8vU0Ywcj8fxrFwZhpSanafU7DztLuP5rBaze5TVicDKeiLICrWqdsEjxLXOaCwAAAAAAFDVEUpVsonnt/La7nAaOp6Zo2OZOTqakaujGfbiz5mu52MZuTqakaOsXIdyHE4dSLXrQKq9zDWEBwV4BlchVtUOc4VWBQFW4VArnNFYAAAAAADAxwilfMRiNqlOmE11wmxlPiYrx6GjmTk6mp7jei4SZB0rGImV6Xo+lpkjw5DSsvOUlp2nPUcyy/Q6gRaTK7gK9XwUHp1VO9SqiKBARQQHKCIoUOFBAQpgRBYAAAAAAKggQqkqLNhqUSNrsBrVCi7T/g6noZSsXHdAdSS9YGSW98exzBxl5jiU6zB0MM2ug2llH40lSSFWi0dQFRHsCqs8w6uSt9sCLBX5WAAAAAAAwBmAUOoMYjGb3KOcyiorx1FycJWZo2MZOTqS4XpOy85TanauMnMckqTMHIcycxxKTq1YvbYAc5GgKlARQQHFgqyIIkFXwTHBgRYuOwQAAAAAoJoilKrhgq0WBVuD1bCMo7EkKdfhVHp+QJWalae07Fz3sus5N39C9xNtadl5+e25SrfnyTAke55Th9LsOlTOEVoFAswm70FW/uWF7kAruEhbfnuoNUBmM6EWAAAAAAD+QCiFcgu0mBWVP0l6RTidhtJz8kMqL6HVibZCQZfHPnlyOA3lOQ33qK6KMJmkcFtBoOUt3PJcL1gOL7TNGsC8WgAAAAAAVAShFHzObDa5RzQpqvzHG4ahzByH+3LCgjCrcGjlOVrLtZxWaFuOwynDUP4+edp3PKtC7yUo0OwxCqsgsPK4LLHoeqHlECuXIAIAAAAAaiZCKVQ7JpNJobYAhdoCFBMZVKFzZOc6PIKsNC+XIxYOudI8tuUp3Z6Xfx6nsnPLP0l8AYvZpPCggEIBVuGAy8sE8UW2cRdEAAAAAEB1RSiFGiko0KKgQIvqh1fseIfTODGvlpe5swqP4ipYLtqW5zTkcBo6npmr45m5kio2WqvgLoje5tGKCA5QpHs5sNiE8RGEWgAAAAAAPyGUAirAYjYpMiRQkSGBFTreMAxl5To859IqcdRWwUgtz21ZuZVzF8RQq8VrYBXpJeDy3BaosKAAWZgsHgAAAABQAYRSgB+YTCaFWAMUYg1QdETFLkHMdTiVVujSwqIjs1KzcpXiMceW534ZOa5QKyPHoYwch/anZFeojnBboUsKCwVWRUdkFdsWHKgw7oAIAAAAADUWoRRQTQVazKodalXtCt4FsSDU8hZYFaynuJeLh1sFI7XS7HlKy59jq7wK7oBYcpjlWg/Ln0Ms1BagUKtFIdYAhdos+esBCgo0M2E8AAAAAFQzhFJADXWqoVZOnlNp2ScfjZWanauUrMLbTuxrz/O8A+Lfxyo2p5bkCrdCC4Iqa4BCbK7gKswWoBDriTbXums/13ZLkfX8/W0BsgUQdAEAAADA6UQoBaBCrAFm1QmzqU6YrULHZ+fPqXWy0Vip+aFXhj1PmXaHMnLylGHPU0aOQ5n5z5JkGFK6veCuiBW7E2JRFrPJI9DyDL1cI7bcI7cKrZcUcoVYLQRdAAAAAFAIoRQAvyi4A2K98IqFWpLkdLomjM/IKRxaFVq357mWc/KXCwKtgv28rBdcluhwGvlzdlXs0kRvAgqCrvxLEcODAhRecOfEINfcW4XbTjwHuO+wGGbjjokAXJ5//nk98cQTSk5OVufOnfXcc8+pV69eXvd9+eWX9dprr2n79u2SpO7du+uRRx4pcX8AAABfIJQCUG2ZzSZ3wKPwyjmnoyDoyg+x3IFWfnB1skDLIwArFJRl5zolSXlOw3254qkIsVrcoVVEkRCLYAuoGd5++21NmTJFCxYsUO/evTV37lzFxsZq586dql+/frH9161bp5EjR6pv374KCgrSY489posvvlg///yzGjVq5Id3AAAAIJkMwzD8XYQvpaamKjIyUikpKYqIiPB3OQBqgDyHU5m5Do9LENPzw6m07Fz3iCz3sr3gLoon2grm4aosIVaLO6QqGmKVJdgKDwqUhTsnooaoin2H3r17q2fPnpo3b54kyel0qkmTJrr11lt1zz33lHq8w+FQVFSU5s2bp9GjR5fpNavi5wAAAKqmsvYbGCkFAKdZgMWsCItZEUGBp3SegsnlC4dY5Qm20rJz3aO2MnMcysxxKDm14vWEWi0egVV4UKDCggIUbnONxgrLH5XlGp0VWGTdtT3UGkC4BZRTTk6OfvjhB02bNs3dZjabNWjQIG3YsKFM58jMzFRubq5q1659usoEAAAoFaEUAFQTpzq5vOQKttLtrpFXpxpsZeQ4lHGKwZbkCrfC3EFVYAmh1on1iKATAVfB9lBbgAK5JBE1xOHDh+VwOBQdHe3RHh0drV9//bVM57j77rvVsGFDDRo0qMR97Ha77PYTN49ITT3FP+wAAABFEEoBQA1iDTCrdoBVtUOtFT5HQbBV+NLCguAqI/8uiGn5lyim5z97rOcfm+twXT1eEG4dOMU7JwYFmhVmOzFvVkGQFV4o0PJcD/QaenGXRJzpHn30US1btkzr1q1TUFBQifvFx8dr1qxZPqwMAADUNIRSAIByqYxgS5LseQ53UJVWKMDyDLVyPUKtNI9gy7W9YORWdq5T2bl2HU4/tXAr0GLyuLww2GpRcKDrEVRo2d1e4nazgorsGxRoIfTCKatbt64sFosOHDjg0X7gwAHFxMSc9Ngnn3xSjz76qD777DN16tTppPtOmzZNU6ZMca+npqaqSZMmFS8cAACgCEIpAIBf2AIssoVZTulyREnKdTiVYfcMrDxHZ+WWMFrLMwhLt+fln8/QscxcHcvMrYy3WYzJpBMhltdQy+wOstyhVtF1q+fxIUXWgwLM3GHxDGa1WtW9e3clJCQoLi5Okmui84SEBE2aNKnE4x5//HE9/PDDWrNmjXr06FHq69hsNtlsp/bnEwAA4GQIpQAA1VqgxaxaIVbVCjm1kVtOp6GMnOKhVnauQ1m5DtdzjkNZuU73emZOnrJynO59XNsdXtcLLlc0jBMTzZ9OVotZQYHmYgFWcGB+iGUNUKj1RKgVYg3Ify68XKjNFqCQ/HMw2sv/pkyZojFjxqhHjx7q1auX5s6dq4yMDI0bN06SNHr0aDVq1Ejx8fGSpMcee0wzZszQ0qVL1bx5cyUnJ0uSwsLCFBYW5rf3AQAAajZCKQAAJJnNpvy7CQZKkZV//lzHifAqO8cVbBUEV15Drfzl4utOZRfa5nF8rkOGK/tSjsOpHIdTqdl5lf5eLGaTO6AKtQUoONCiUJsr6AoJtCjEdrKg68RysNWi0ELLIdyNscyGDx+uQ4cOacaMGUpOTlaXLl30ySefuCc/T0pKktl8YrTc/PnzlZOTo6uuusrjPA888IBmzpzpy9IBAADcTIZR0H2tGVJTUxUZGamUlBRFRET4uxwAACqNYRiy5zk9Ai1voVfBSK2snDxl5LjaM4ssF+yTac9TZv4xOXnO0/4ebAFmd9BVeIRW0dFaoTbPoKtlvTD1aF77tNRE38GFzwEAAJRVWfsNjJQCAOAMYTKZFJR/qV7UaTh/nsOpzPxwK8NeKLjKyXO15QddmUWWM4sGXYXWXcfluUd42fOcsufllLu2K7o1Om2hFAAAAE4PQikAAFAmARazIixmRQQFVup5C0Z4FQRdWbmu0CsrP8DKyDmxnFlC0NW+4Wm45hIAAACnFaEUAADwq8IjvOr4uxgAAAD4TJW4X/Tzzz+v5s2bKygoSL1799bGjRtL3HfJkiUymUwej6CgIB9WCwAAAAAAgFPl91Dq7bff1pQpU/TAAw9oy5Yt6ty5s2JjY3Xw4MESj4mIiND+/fvdj7179/qwYgAAAAAAAJwqv4dSTz31lG688UaNGzdO7dq104IFCxQSEqJFixaVeIzJZFJMTIz7UXD7YwAAAAAAAFQPfg2lcnJy9MMPP2jQoEHuNrPZrEGDBmnDhg0lHpeenq5mzZqpSZMmuvzyy/Xzzz+XuK/dbldqaqrHAwAAAAAAAP7l11Dq8OHDcjgcxUY6RUdHKzk52esx55xzjhYtWqT3339fb7zxhpxOp/r27au///7b6/7x8fGKjIx0P5o0aVLp7wMAAAAAAADl4/fL98qrT58+Gj16tLp06aIBAwbovffeU7169fTiiy963X/atGlKSUlxP/766y8fVwwAAAAAAICiAvz54nXr1pXFYtGBAwc82g8cOKCYmJgynSMwMFBdu3bVrl27vG632Wyy2WynXCsAAAAAAAAqj19HSlmtVnXv3l0JCQnuNqfTqYSEBPXp06dM53A4HNq2bZsaNGhwusoEAAAAAABAJfPrSClJmjJlisaMGaMePXqoV69emjt3rjIyMjRu3DhJ0ujRo9WoUSPFx8dLkmbPnq1zzz1XrVq10vHjx/XEE09o7969mjBhgj/fBgAAAAAAAMrB76HU8OHDdejQIc2YMUPJycnq0qWLPvnkE/fk50lJSTKbTwzoOnbsmG688UYlJycrKipK3bt317fffqt27dr56y0AAAAAAACgnEyGYRj+LsKXUlNTFRkZqZSUFEVERPi7HAAAUMXRd3DhcwAAAGVV1n5Dtbv7HgAAAAAAAKo/QikAAAAAAAD4HKEUAAAAAAAAfI5QCgAAAAAAAD5HKAUAAAAAAACfI5QCAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUAAAAAAADgc4RSAAAAAAAA8DlCKQAAAAAAAPgcoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUAAAAAAAAfI5QCgAAAAAAAD5HKAUAAAAAAACfI5QCAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUAAAAAAADgc4RSAAAAAAAA8DlCKQAAAAAAAPgcoRQAAAAAAAB8jlAKAAAAAAAAPkcoBQAAAAAAAJ8jlAIAAAAAAIDPEUoBAAAAAADA5wilAAAAAAAA4HOEUgAAAAAAAPA5QikAAAAAAAD4HKEUAAAAAAAAfI5QCgAAAAAAAD5HKAUAAAAAAACfI5QCAAAAAACAzxFKAQAAAAAAwOcIpQAAAAAAAOBzVSKUev7559W8eXMFBQWpd+/e2rhx40n3X758udq0aaOgoCB17NhRq1ev9lGlAAAAVQP9JwAAUN35PZR6++23NWXKFD3wwAPasmWLOnfurNjYWB08eNDr/t9++61Gjhyp8ePH68cff1RcXJzi4uK0fft2H1cOAADgH/SfAADAmcBkGIbhzwJ69+6tnj17at68eZIkp9OpJk2a6NZbb9U999xTbP/hw4crIyNDH330kbvt3HPPVZcuXbRgwYJSXy81NVWRkZFKSUlRRERE5b0RAABwRqqKfQdf95+kqvk5AACAqqms/Qa/jpTKycnRDz/8oEGDBrnbzGazBg0apA0bNng9ZsOGDR77S1JsbGyJ+wMAAJxJ6D8BAIAzRYA/X/zw4cNyOByKjo72aI+Ojtavv/7q9Zjk5GSv+ycnJ3vd3263y263u9dTUlIkuVI7AACA0lS1PoMv+k8SfSgAAFBxBf2F0i7O82so5Qvx8fGaNWtWsfYmTZr4oRoAAIDqgT4UAAA4VWlpaYqMjCxxu19Dqbp168pisejAgQMe7QcOHFBMTIzXY2JiYsq1/7Rp0zRlyhT3utPp1NGjR1WnTh2ZTKZTfAc1Q2pqqpo0aaK//vqLOSSqOH5W1QM/p+qBn1P1cbp/VgXf8IWHh1f6uSvCF/0niT5UZeDvkeqBn1P1wM+p+uBnVT34ov+Ulpamhg0bnnQ/v4ZSVqtV3bt3V0JCguLi4iS5OjwJCQmaNGmS12P69OmjhIQETZ482d22du1a9enTx+v+NptNNpvNo61WrVqVUX6NExERwV8q1QQ/q+qBn1P1wM+p+qgpPytf9J8k+lCVqab8blZ3/JyqB35O1Qc/q+rhdP6cTjZCqoDfL9+bMmWKxowZox49eqhXr16aO3euMjIyNG7cOEnS6NGj1ahRI8XHx0uSbr/9dg0YMEBz5szRpZdeqmXLlmnz5s166aWX/Pk2AAAAfIb+EwAAOBP4PZQaPny4Dh06pBkzZig5OVldunTRJ5984p6MMykpSWbziZsE9u3bV0uXLtX06dN17733qnXr1lq5cqU6dOjgr7cAAADgU/SfAADAmcDvoZQkTZo0qcTh5uvWrSvWdvXVV+vqq68+zVWhgM1m0wMPPFBsCD+qHn5W1QM/p+qBn1P1UVN/VvSfqr6a+rtZ3fBzqh74OVUf/Kyqh6ryczIZpd2fDwAAAAAAAKhk5tJ3AQAAAAAAACoXoRQAAAAAAAB8jlAKAAAAAAAAPkcohRLFx8erZ8+eCg8PV/369RUXF6edO3f6uyyU4tFHH5XJZNLkyZP9XQq82Ldvn66//nrVqVNHwcHB6tixozZv3uzvslCIw+HQ/fffrxYtWig4OFgtW7bUgw8+KKZg9K+vvvpKQ4cOVcOGDWUymbRy5UqP7YZhaMaMGWrQoIGCg4M1aNAg/f777/4pFjUa/afqif5T1Ub/qeqj/1R1VfU+FKEUSvTll19q4sSJ+u6777R27Vrl5ubq4osvVkZGhr9LQwk2bdqkF198UZ06dfJ3KfDi2LFj6tevnwIDA/Xxxx/rl19+0Zw5cxQVFeXv0lDIY489pvnz52vevHnasWOHHnvsMT3++ON67rnn/F1ajZaRkaHOnTvr+eef97r98ccf17PPPqsFCxbo+++/V2hoqGJjY5Wdne3jSlHT0X+qfug/VW30n6oH+k9VV1XvQ3H3PZTZoUOHVL9+fX355Zfq37+/v8tBEenp6erWrZteeOEFPfTQQ+rSpYvmzp3r77JQyD333KP169fr66+/9ncpOInLLrtM0dHRWrhwobvtyiuvVHBwsN544w0/VoYCJpNJK1asUFxcnCTXN3wNGzbUnXfeqalTp0qSUlJSFB0drSVLlmjEiBF+rBY1Hf2nqo3+U9VH/6l6oP9UPVTFPhQjpVBmKSkpkqTatWv7uRJ4M3HiRF166aUaNGiQv0tBCT744AP16NFDV199terXr6+uXbvq5Zdf9ndZKKJv375KSEjQb7/9JknaunWrvvnmGw0ePNjPlaEku3fvVnJyssfff5GRkerdu7c2bNjgx8oA+k9VHf2nqo/+U/VA/6l6qgp9qACfvAqqPafTqcmTJ6tfv37q0KGDv8tBEcuWLdOWLVu0adMmf5eCk/jzzz81f/58TZkyRffee682bdqk2267TVarVWPGjPF3ech3zz33KDU1VW3atJHFYpHD4dDDDz+s6667zt+loQTJycmSpOjoaI/26Oho9zbAH+g/VW30n6oH+k/VA/2n6qkq9KEIpVAmEydO1Pbt2/XNN9/4uxQU8ddff+n222/X2rVrFRQU5O9ycBJOp1M9evTQI488Iknq2rWrtm/frgULFtCpqkLeeecdvfnmm1q6dKnat2+vxMRETZ48WQ0bNuTnBKBc6D9VXfSfqg/6T9UD/SdUFJfvoVSTJk3SRx99pC+++EKNGzf2dzko4ocfftDBgwfVrVs3BQQEKCAgQF9++aWeffZZBQQEyOFw+LtE5GvQoIHatWvn0da2bVslJSX5qSJ489///lf33HOPRowYoY4dO2rUqFG64447FB8f7+/SUIKYmBhJ0oEDBzzaDxw44N4G+Br9p6qN/lP1Qf+peqD/VD1VhT4UoRRKZBiGJk2apBUrVujzzz9XixYt/F0SvLjwwgu1bds2JSYmuh89evTQddddp8TERFksFn+XiHz9+vUrdlvw3377Tc2aNfNTRfAmMzNTZrPnP48Wi0VOp9NPFaE0LVq0UExMjBISEtxtqamp+v7779WnTx8/VoaaiP5T9UD/qfqg/1Q90H+qnqpCH4rL91CiiRMnaunSpXr//fcVHh7uvqY0MjJSwcHBfq4OBcLDw4vNUxEaGqo6deowf0UVc8cdd6hv37565JFHdM0112jjxo166aWX9NJLL/m7NBQydOhQPfzww2ratKnat2+vH3/8UU899ZRuuOEGf5dWo6Wnp2vXrl3u9d27dysxMVG1a9dW06ZNNXnyZD300ENq3bq1WrRoofvvv18NGzZ0310G8BX6T9UD/afqg/5T9UD/qeqq8n0oAyiBJK+PxYsX+7s0lGLAgAHG7bff7u8y4MWHH35odOjQwbDZbEabNm2Ml156yd8loYjU1FTj9ttvN5o2bWoEBQUZZ511lnHfffcZdrvd36XVaF988YXXf5PGjBljGIZhOJ1O4/777zeio6MNm81mXHjhhcbOnTv9WzRqJPpP1Rf9p6qL/lPVR/+p6qrqfSiTYRiGb+IvAAAAAAAAwIU5pQAAAAAAAOBzhFIAAAAAAADwOUIpAAAAAAAA+ByhFAAAAAAAAHyOUAoAAAAAAAA+RygFAAAAAAAAnyOUAgAAAAAAgM8RSgEAAAAAAMDnCKUA4BSZTCatXLnS32UAAABUG/SfAEiEUgCqubFjx8pkMhV7XHLJJf4uDQAAoEqi/wSgqgjwdwEAcKouueQSLV682KPNZrP9f3v38wr7F8dx/DWDNDNRw4SxkmhCsSFNbLDQWBFJTZrd5NdkY8fNWNiynFLsRFFKCcVySmwwi+Ef0IRszBQb5y5uTX26fb99+14+Zm7PR33qc875fGbe7927d2fOfFM0AAAAhY/6CUAhYKcUgKJXXl6uuro6y+X1eiX92hqeSCQUCoXkcrnU2Nio/f19y/upVEr9/f1yuVyqrq5WNBpVNpu1PLO1taW2tjaVl5fL7/drbm7Osv78/KyRkRG53W41Nzfr8PDwa5MGAAD4A9RPAAoBTSkAf70fP35odHRUNzc3CofDmpiYUDqdliTlcjkNDg7K6/Xq6upKe3t7Ojs7sxRNiURCs7OzikajSqVSOjw8VFNTk+U7VlZWND4+rtvbWw0NDSkcDuvl5cXWPAEAAD4L9RMAWxgAKGKRSMSUlJQYj8djuVZXV40xxkgyU1NTlne6u7vN9PS0McaYjY0N4/V6TTabza8fHR0Zp9NpMpmMMcaY+vp6s7i4+I8xSDJLS0v5cTabNZLM8fHxp+UJAADwWaifABQKzpQCUPT6+vqUSCQsc1VVVfn7YDBoWQsGg7q+vpYkpdNpdXR0yOPx5Nd7enr08fGh+/t7ORwOPTw8aGBg4F9jaG9vz997PB5VVlbq8fHx/6YEAADwpaifABQCmlIAip7H4/ltO/hncblc/+m5srIyy9jhcOjj4+MrQgIAAPhj1E8ACgFnSgH4611cXPw2bmlpkSS1tLTo5uZGuVwuv55MJuV0OhUIBFRRUaGGhgadn5/bGjMAAMB3on4CYAd2SgEoeu/v78pkMpa50tJS+Xw+SdLe3p46OzvV29ur7e1tXV5eanNzU5IUDoe1vLysSCSieDyup6cnxWIxTU5Oqra2VpIUj8c1NTWlmpoahUIhvb6+KplMKhaL2ZsoAADAJ6F+AlAIaEoBKHonJyfy+/2WuUAgoLu7O0m//tlld3dXMzMz8vv92tnZUWtrqyTJ7Xbr9PRU8/Pz6urqktvt1ujoqNbW1vKfFYlE9Pb2pvX1dS0sLMjn82lsbMy+BAEAAD4Z9ROAQuAwxpjvDgIAvorD4dDBwYGGh4e/OxQAAICiQP0EwC6cKQUAAAAAAADb0ZQCAAAAAACA7fj5HgAAAAAAAGzHTikAAAAAAADYjqYUAAAAAAAAbEdTCgAAAAAAALajKQUAAAAAAADb0ZQCAAAAAACA7WhKAQAAAAAAwHY0pQAAAAAAAGA7mlIAAAAAAACwHU0pAAAAAAAA2O4nhAKigp9X4MMAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extracting data for plotting\n",
        "train_losses = history['train_loss']\n",
        "train_accuracies = history['train_accuracy']\n",
        "val_losses = history['val_loss']\n",
        "val_accuracies = history['val_accuracy']\n",
        "epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, train_losses, label='Training Loss')\n",
        "plt.plot(epochs, val_losses, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.ylim(0, 3)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylim(0, 1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksfu_3QoFO-m"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "13583170358c4c0da03ab7252553976e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e50ba2d39a374e9096c112ad4798e3f5",
              "IPY_MODEL_316e81bafbb64beb8db9d30f37a2ec03",
              "IPY_MODEL_8aaf4e25d45842b58dc62d1c7ee68d69"
            ],
            "layout": "IPY_MODEL_5518e78b3c1248cdbca2ccaee224ad63"
          }
        },
        "316e81bafbb64beb8db9d30f37a2ec03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_85b5bc6751764beab6689e6dcdaec549",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5936b8de2f54622a0a8512418647923",
            "value": 10
          }
        },
        "5518e78b3c1248cdbca2ccaee224ad63": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6744fd744e084633ac5a93bd05ab0037": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "683b8cc4e9bf43cdb43595ffb3746db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "786a4ea44f7340b988d9c94323e62a38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b7efc4cb753414185b700dddd363d11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b5bc6751764beab6689e6dcdaec549": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8aaf4e25d45842b58dc62d1c7ee68d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_786a4ea44f7340b988d9c94323e62a38",
            "placeholder": "​",
            "style": "IPY_MODEL_683b8cc4e9bf43cdb43595ffb3746db1",
            "value": " 10/10 [03:43&lt;00:00, 22.09s/it]"
          }
        },
        "d5936b8de2f54622a0a8512418647923": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e50ba2d39a374e9096c112ad4798e3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b7efc4cb753414185b700dddd363d11",
            "placeholder": "​",
            "style": "IPY_MODEL_6744fd744e084633ac5a93bd05ab0037",
            "value": "Training Progress: 100%"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
